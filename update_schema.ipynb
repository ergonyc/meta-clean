{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASAP CRN Metadata validation - wave 1\n",
    "\n",
    "# ASAP CRN Metadata validation - wave 1\n",
    "\n",
    "15 September 2023\n",
    "Andy Henrie\n",
    "\n",
    "\n",
    "\n",
    "## STEPS\n",
    "\n",
    "### imports\n",
    "- pandas\n",
    "- pathlib\n",
    "\n",
    "### Load CDE for validation\n",
    "- check all columns\n",
    "\n",
    "### Team Lee\n",
    "- load .tsv, csv tables\n",
    "- fix format\n",
    "- load additional metadata\n",
    "\n",
    "- add batch columns\n",
    "- add missing columns\n",
    "\n",
    "\n",
    "### Team Hafler\n",
    "- load excel file with tables\n",
    "- add batch info\n",
    "- add missing columns\n",
    "\n",
    "\n",
    "\n",
    "### Team Hardy\n",
    "- load excel file with tables\n",
    "- add batch info\n",
    "- add missing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# local helpers\n",
    "from utils.qcutils import validate_table, force_enum_string, reorder_table_to_CDE\n",
    "from utils.io import ReportCollector, get_dtypes_dict, read_meta_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDE_path = Path.cwd() / \"ASAP_CDE_v1.csv\" \n",
    "\n",
    "CDEv1 = pd.read_csv( Path.cwd() / \"ASAP_CDE_v1.csv\" )\n",
    "CDEv2 = pd.read_csv( Path.cwd() / \"ASAP_CDE_v2.csv\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create helpers - port_v1_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_path = Path.cwd() / \"clean/team-Hardy\"\n",
    "\n",
    "# Initialize the data types dictionary\n",
    "dtypes_dict = get_dtypes_dict(CDEv1)\n",
    "\n",
    "SUBJECT = read_meta_table(f\"{tables_path}/SUBJECT.csv\", dtypes_dict)\n",
    "CLINPATH = read_meta_table(f\"{tables_path}/CLINPATH.csv\", dtypes_dict)\n",
    "STUDY = read_meta_table(f\"{tables_path}/STUDY.csv\", dtypes_dict)\n",
    "PROTOCOL = read_meta_table(f\"{tables_path}/PROTOCOL.csv\", dtypes_dict)\n",
    "SAMPLE = read_meta_table(f\"{tables_path}/SAMPLE.csv\", dtypes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDY: add preprocessing_references\n",
    "STUDYv2 = STUDY.copy()\n",
    "\n",
    "assert len(SAMPLE['preprocessing_references'].unique()) == 1\n",
    "STUDYv2['preprocessing_references'] = SAMPLE['preprocessing_references'][0]\n",
    "\n",
    "STUDYv2['team_dataset_id'] = STUDYv2['project_dataset'].str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "\n",
    "\n",
    "# PROTOCOL\n",
    "# no change\n",
    "PROTOCOLv2 = PROTOCOL.copy()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMP_CLIN = SAMPLE.merge(CLINPATH, on=\"sample_id\", how=\"left\")\n",
    "\n",
    "SAMP_CLIN['source_sample_id'] = SAMP_CLIN['source_sample_id_x']\n",
    "SAMP_CLIN = SAMP_CLIN.drop(columns=['source_sample_id_x','source_sample_id_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>source_subject_id</th>\n",
       "      <th>biobank_name</th>\n",
       "      <th>organism</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_at_collection</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>duration_pmi</th>\n",
       "      <th>primary_diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>path_nia_aa_a</th>\n",
       "      <th>path_nia_aa_b</th>\n",
       "      <th>path_nia_aa_c</th>\n",
       "      <th>TDP43</th>\n",
       "      <th>arteriolosclerosis_severity_scale</th>\n",
       "      <th>amyloid_angiopathy_severity_scale</th>\n",
       "      <th>path_ad_level</th>\n",
       "      <th>dig_slide_avail</th>\n",
       "      <th>quant_path_avail</th>\n",
       "      <th>source_sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>QSBB_UK</td>\n",
       "      <td>Human</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Idiopathic PD</td>\n",
       "      <td>...</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>QSBB_UK</td>\n",
       "      <td>Human</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Idiopathic PD</td>\n",
       "      <td>...</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>QSBB_UK</td>\n",
       "      <td>Human</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Idiopathic PD</td>\n",
       "      <td>...</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>QSBB_UK</td>\n",
       "      <td>Human</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Idiopathic PD</td>\n",
       "      <td>...</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>QSBB_UK</td>\n",
       "      <td>Human</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Idiopathic PD</td>\n",
       "      <td>...</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id source_subject_id biobank_name organism     sex  \\\n",
       "0      babom             P2/14      QSBB_UK    Human  Female   \n",
       "1      babom             P2/14      QSBB_UK    Human  Female   \n",
       "2      babom             P2/14      QSBB_UK    Human  Female   \n",
       "3      babom             P2/14      QSBB_UK    Human  Female   \n",
       "4      babom             P2/14      QSBB_UK    Human  Female   \n",
       "\n",
       "   age_at_collection  race ethnicity  duration_pmi primary_diagnosis  ...  \\\n",
       "0                 78  <NA>      <NA>          46.0     Idiopathic PD  ...   \n",
       "1                 78  <NA>      <NA>          46.0     Idiopathic PD  ...   \n",
       "2                 78  <NA>      <NA>          46.0     Idiopathic PD  ...   \n",
       "3                 78  <NA>      <NA>          46.0     Idiopathic PD  ...   \n",
       "4                 78  <NA>      <NA>          46.0     Idiopathic PD  ...   \n",
       "\n",
       "  path_nia_aa_a path_nia_aa_b path_nia_aa_c  TDP43  \\\n",
       "0            A2            B1            C2   <NA>   \n",
       "1            A2            B1            C2   <NA>   \n",
       "2            A2            B1            C2   <NA>   \n",
       "3            A2            B1            C2   <NA>   \n",
       "4            A2            B1            C2   <NA>   \n",
       "\n",
       "   arteriolosclerosis_severity_scale amyloid_angiopathy_severity_scale  \\\n",
       "0                               <NA>                              <NA>   \n",
       "1                               <NA>                              <NA>   \n",
       "2                               <NA>                              <NA>   \n",
       "3                               <NA>                              <NA>   \n",
       "4                               <NA>                              <NA>   \n",
       "\n",
       "                                       path_ad_level dig_slide_avail  \\\n",
       "0  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "1  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "2  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "3  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "4  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "\n",
       "   quant_path_avail  source_sample_id  \n",
       "0               Yes              <NA>  \n",
       "1               Yes              <NA>  \n",
       "2               Yes              <NA>  \n",
       "3               Yes              <NA>  \n",
       "4               Yes              <NA>  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SUBJ_SAMP_CLIN = SUBJECT.merge(SAMP_CLIN, on=\"subject_id\", how=\"left\")\n",
    "SUBJ_SAMP_CLIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUBJECT_cde_df = CDEv2[CDEv2['Table'] == \"SUBJECT\"]\n",
    "SUBJECT_cols = SUBJECT_cde_df[\"Field\"].to_list()\n",
    "SUBJECTv2 = SUBJ_SAMP_CLIN[SUBJECT_cols].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>source_subject_id</th>\n",
       "      <th>duration_pmi</th>\n",
       "      <th>path_autopsy_dx_main</th>\n",
       "      <th>path_autopsy_second_dx</th>\n",
       "      <th>path_autopsy_third_dx</th>\n",
       "      <th>path_autopsy_fourth_dx</th>\n",
       "      <th>path_autopsy_fifth_dx</th>\n",
       "      <th>path_autopsy_sixth_dx</th>\n",
       "      <th>path_autopsy_seventh_dx</th>\n",
       "      <th>...</th>\n",
       "      <th>path_nia_ri</th>\n",
       "      <th>path_nia_aa_a</th>\n",
       "      <th>path_nia_aa_b</th>\n",
       "      <th>path_nia_aa_c</th>\n",
       "      <th>TDP43</th>\n",
       "      <th>arteriolosclerosis_severity_scale</th>\n",
       "      <th>amyloid_angiopathy_severity_scale</th>\n",
       "      <th>path_ad_level</th>\n",
       "      <th>dig_slide_avail</th>\n",
       "      <th>quant_path_avail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Parkinson's disease with dementia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Parkinson's disease with dementia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Parkinson's disease with dementia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Parkinson's disease with dementia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babom</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Parkinson's disease with dementia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Low level Alzheimer's disease neuropathologica...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id source_subject_id  duration_pmi  \\\n",
       "0      babom             P2/14          46.0   \n",
       "1      babom             P2/14          46.0   \n",
       "2      babom             P2/14          46.0   \n",
       "3      babom             P2/14          46.0   \n",
       "4      babom             P2/14          46.0   \n",
       "\n",
       "                path_autopsy_dx_main path_autopsy_second_dx  \\\n",
       "0  Parkinson's disease with dementia                   none   \n",
       "1  Parkinson's disease with dementia                   none   \n",
       "2  Parkinson's disease with dementia                   none   \n",
       "3  Parkinson's disease with dementia                   none   \n",
       "4  Parkinson's disease with dementia                   none   \n",
       "\n",
       "  path_autopsy_third_dx path_autopsy_fourth_dx path_autopsy_fifth_dx  \\\n",
       "0                  none                   none                  none   \n",
       "1                  none                   none                  none   \n",
       "2                  none                   none                  none   \n",
       "3                  none                   none                  none   \n",
       "4                  none                   none                  none   \n",
       "\n",
       "  path_autopsy_sixth_dx path_autopsy_seventh_dx  ... path_nia_ri  \\\n",
       "0                  none                    none  ...        <NA>   \n",
       "1                  none                    none  ...        <NA>   \n",
       "2                  none                    none  ...        <NA>   \n",
       "3                  none                    none  ...        <NA>   \n",
       "4                  none                    none  ...        <NA>   \n",
       "\n",
       "   path_nia_aa_a path_nia_aa_b path_nia_aa_c TDP43  \\\n",
       "0             A2            B1            C2  <NA>   \n",
       "1             A2            B1            C2  <NA>   \n",
       "2             A2            B1            C2  <NA>   \n",
       "3             A2            B1            C2  <NA>   \n",
       "4             A2            B1            C2  <NA>   \n",
       "\n",
       "  arteriolosclerosis_severity_scale  amyloid_angiopathy_severity_scale  \\\n",
       "0                              <NA>                               <NA>   \n",
       "1                              <NA>                               <NA>   \n",
       "2                              <NA>                               <NA>   \n",
       "3                              <NA>                               <NA>   \n",
       "4                              <NA>                               <NA>   \n",
       "\n",
       "                                       path_ad_level dig_slide_avail  \\\n",
       "0  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "1  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "2  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "3  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "4  Low level Alzheimer's disease neuropathologica...             Yes   \n",
       "\n",
       "  quant_path_avail  \n",
       "0              Yes  \n",
       "1              Yes  \n",
       "2              Yes  \n",
       "3              Yes  \n",
       "4              Yes  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CLINPATH_cde_df = CDEv2[CDEv2['Table'] == \"CLINPATH\"]\n",
    "\n",
    "CLINPATH_cols = CLINPATH_cde_df[\"Field\"].to_list()\n",
    "CLINPATHv2 = SUBJ_SAMP_CLIN[CLINPATH_cols]\n",
    "CLINPATHv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_cde_df = CDEv2[CDEv2['Table'] == \"SAMPLE\"]\n",
    "SAMPLE_cols = SAMPLE_cde_df[\"Field\"].to_list()\n",
    "SAMPLEv2 = SUBJ_SAMP_CLIN[SAMPLE_cols].drop_duplicates(inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_cde_df = CDEv2[CDEv2['Table'] == \"DATA\"]\n",
    "DATA_cols = DATA_cde_df[\"Field\"].to_list()\n",
    "DATAv2 = SAMPLE[DATA_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tables_to_CDEv2(tables_path: str|Path, out_dir: str, CDEv1: pd.DataFrame, CDEv2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    load the tables from the tables_path, and update them to the CDEv2 schema.  export the new tables to a datstamped out_dir\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "\n",
    "    # Get the current date and time\n",
    "    current_date = datetime.datetime.now()\n",
    "\n",
    "   \n",
    "    # Initialize the data types dictionary\n",
    "    dtypes_dict = get_dtypes_dict(CDEv1)\n",
    "        \n",
    "    STUDY = read_meta_table(f\"{tables_path}/STUDY.csv\", dtypes_dict)\n",
    "    PROTOCOL = read_meta_table(f\"{tables_path}/PROTOCOL.csv\", dtypes_dict)\n",
    "    SUBJECT = read_meta_table(f\"{tables_path}/SUBJECT.csv\", dtypes_dict)\n",
    "    CLINPATH = read_meta_table(f\"{tables_path}/CLINPATH.csv\", dtypes_dict)\n",
    "    SAMPLE = read_meta_table(f\"{tables_path}/SAMPLE.csv\", dtypes_dict)\n",
    "\n",
    "    # STUDY\n",
    "    STUDYv2 = STUDY.copy() # don't really need to copy here\n",
    "    assert len(SAMPLE['preprocessing_references'].unique()) == 1\n",
    "    STUDYv2['preprocessing_references'] = SAMPLE['preprocessing_references'][0]\n",
    "    STUDYv2['team_dataset_id'] = STUDYv2['project_dataset'].str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "\n",
    "    # PROTOCOL\n",
    "    PROTOCOLv2 = PROTOCOL.copy()  \n",
    "\n",
    "    SAMP_CLIN = SAMPLE.merge(CLINPATH, on=\"sample_id\", how=\"left\")\n",
    "    SAMP_CLIN['source_sample_id'] = SAMP_CLIN['source_sample_id_x']\n",
    "    SAMP_CLIN = SAMP_CLIN.drop(columns=['source_sample_id_x','source_sample_id_y'])\n",
    "\n",
    "    SUBJ_SAMP_CLIN = SUBJECT.merge(SAMP_CLIN, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "\n",
    "    SUBJECT_cde_df = CDEv2[CDEv2['Table'] == \"SUBJECT\"]\n",
    "    SUBJECT_cols = SUBJECT_cde_df[\"Field\"].to_list()\n",
    "    SUBJECTv2 = SUBJ_SAMP_CLIN[SUBJECT_cols]\n",
    "    SUBJECTv2 = SUBJ_SAMP_CLIN[SUBJECT_cols].drop_duplicates(inplace=False).reset_index()\n",
    "\n",
    "    CLINPATH_cde_df = CDEv2[CDEv2['Table'] == \"CLINPATH\"]\n",
    "    CLINPATH_cols = CLINPATH_cde_df[\"Field\"].to_list()\n",
    "    CLINPATHv2 = SUBJ_SAMP_CLIN[CLINPATH_cols]\n",
    "\n",
    "    SAMPLE_cde_df = CDEv2[CDEv2['Table'] == \"SAMPLE\"]\n",
    "    SAMPLE_cols = SAMPLE_cde_df[\"Field\"].to_list()\n",
    "    # SAMPLEv2 = SUBJ_SAMP_CLIN[SAMPLE_cols]\n",
    "    SAMPLEv2 = SUBJ_SAMP_CLIN[SAMPLE_cols].drop_duplicates(inplace=False).reset_index()\n",
    "\n",
    "    DATA_cde_df = CDEv2[CDEv2['Table'] == \"DATA\"]\n",
    "    DATA_cols = DATA_cde_df[\"Field\"].to_list()\n",
    "    DATAv2 = SAMPLE[DATA_cols]\n",
    "\n",
    "\n",
    "    STUDYv2 = reorder_table_to_CDE(STUDYv2, \"STUDY\", CDEv2)\n",
    "    PROTOCOLv2 = reorder_table_to_CDE(PROTOCOLv2, \"PROTOCOL\", CDEv2)\n",
    "    CLINPATHv2 = reorder_table_to_CDE(CLINPATHv2, \"CLINPATH\", CDEv2)\n",
    "    SAMPLEv2 = reorder_table_to_CDE(SAMPLEv2, \"SAMPLE\", CDEv2)\n",
    "    SUBJECTv2 = reorder_table_to_CDE(SUBJECTv2, \"SUBJECT\", CDEv2)\n",
    "    DATAv2 = reorder_table_to_CDE(DATAv2, \"DATA\", CDEv2)\n",
    "\n",
    "    # Format the date as a string in the format 'YYYYMMDD'\n",
    "    date_str = current_date.strftime('%Y%m%d')\n",
    "\n",
    "    tables_path = Path(tables_path)\n",
    "\n",
    "    export_root = tables_path / f\"{out_dir}_{date_str}\"\n",
    "    if not export_root.exists():\n",
    "        export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    STUDYv2.to_csv( export_root / \"STUDY.csv\")\n",
    "    PROTOCOLv2.to_csv(export_root / \"PROTOCOL.csv\")\n",
    "    SAMPLEv2.to_csv(export_root / \"SAMPLE.csv\")\n",
    "    SUBJECTv2.to_csv(export_root / \"SUBJECT.csv\")\n",
    "    CLINPATHv2.to_csv(export_root / \"CLINPATH.csv\")\n",
    "    DATAv2.to_csv(export_root / \"DATA.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    return STUDYv2, PROTOCOLv2, SAMPLEv2, SUBJECTv2, CLINPATHv2, DATAv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDE_path = Path.cwd() / \"ASAP_CDE_v1.csv\" \n",
    "\n",
    "CDEv1 = pd.read_csv( Path.cwd() / \"ASAP_CDE_v1.csv\" )\n",
    "CDEv2 = pd.read_csv( Path.cwd() / \"ASAP_CDE_v2.csv\" )\n",
    "\n",
    "STUDYv2, PROTOCOLv2, SAMPLEv2, SUBJECTv2, CLINPATHv2, DATAv2 = update_tables_to_CDEv2(tables_path, \"v2\", CDEv1, CDEv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>source_sample_id</th>\n",
       "      <th>replicate</th>\n",
       "      <th>replicate_count</th>\n",
       "      <th>repeated_sample</th>\n",
       "      <th>batch</th>\n",
       "      <th>tissue</th>\n",
       "      <th>brain_region</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_ontology_term_id</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>DV200</th>\n",
       "      <th>pm_PH</th>\n",
       "      <th>donor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>babom</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BATCH_2</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>Left</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babom_IPL</td>\n",
       "      <td>babom</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BATCH_2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>Left</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borah_ACG</td>\n",
       "      <td>borah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BATCH_2</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000384 (male)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>borah_IPL</td>\n",
       "      <td>borah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>rep1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BATCH_2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000384 (male)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borah_IPL</td>\n",
       "      <td>borah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BATCH_5</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000384 (male)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id subject_id source_sample_id replicate  replicate_count  \\\n",
       "0  babom_ACG      babom             <NA>      <NA>                1   \n",
       "1  babom_IPL      babom             <NA>      <NA>                1   \n",
       "2  borah_ACG      borah             <NA>      <NA>                1   \n",
       "3  borah_IPL      borah             <NA>      rep1                2   \n",
       "4  borah_IPL      borah             <NA>      rep2                2   \n",
       "\n",
       "   repeated_sample    batch tissue brain_region hemisphere  ...  \\\n",
       "0                0  BATCH_2  brain          ACG       Left  ...   \n",
       "1                0  BATCH_2  brain          IPL       Left  ...   \n",
       "2                0  BATCH_2  brain          ACG      Right  ...   \n",
       "3                1  BATCH_2  brain          IPL      Right  ...   \n",
       "4                1  BATCH_5  brain          IPL      Right  ...   \n",
       "\n",
       "    sex_ontology_term_id self_reported_ethnicity_ontology_term_id  \\\n",
       "0  PATO:0000383 (female)                                     <NA>   \n",
       "1  PATO:0000383 (female)                                     <NA>   \n",
       "2    PATO:0000384 (male)                                     <NA>   \n",
       "3    PATO:0000384 (male)                                     <NA>   \n",
       "4    PATO:0000384 (male)                                     <NA>   \n",
       "\n",
       "  disease_ontology_term_id  tissue_ontology_term_id  \\\n",
       "0            MONDO:0005180           UBERON:0009835   \n",
       "1            MONDO:0005180           UBERON:0006088   \n",
       "2            MONDO:0005180           UBERON:0009835   \n",
       "3            MONDO:0005180           UBERON:0006088   \n",
       "4            MONDO:0005180           UBERON:0006088   \n",
       "\n",
       "   cell_type_ontology_term_id assay_ontology_term_id  suspension_type DV200  \\\n",
       "0                        <NA>            EFO:0008913          nucleus   NaN   \n",
       "1                        <NA>            EFO:0008913          nucleus   NaN   \n",
       "2                        <NA>            EFO:0008913          nucleus   NaN   \n",
       "3                        <NA>            EFO:0008913          nucleus   NaN   \n",
       "4                        <NA>            EFO:0008913          nucleus   NaN   \n",
       "\n",
       "  pm_PH donor_id  \n",
       "0   NaN     <NA>  \n",
       "1   NaN     <NA>  \n",
       "2   NaN     <NA>  \n",
       "3   NaN     <NA>  \n",
       "4   NaN     <NA>  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLEv2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write clean metadata tables according to CDE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE = SAMPLE[CDE[CDE[\"Table\"]==\"SAMPLE\"].Field.tolist()]\n",
    "\n",
    "\n",
    "def reorder_table_to_CDE(df, df_name, CDE):\n",
    "    col_order = CDE[CDE[\"Table\"]==df_name].Field.tolist()\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    for col in col_order:\n",
    "        if col in df.columns:   \n",
    "            df_out[col] = df[col]\n",
    "        else:\n",
    "            df_out[col] = \"\"\n",
    "\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write clean metadata tables according to CDE \n",
    "# SAMPLE = SAMPLE[CDE[CDE[\"Table\"]==\"SAMPLE\"].Field.tolist()]\n",
    "\n",
    "\n",
    "def reorder_table_to_CDE(df, df_name, CDE):\n",
    "    col_order = CDE[CDE[\"Table\"]==df_name].Field.tolist()\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    for col in col_order:\n",
    "        if col in df.columns:   \n",
    "            df_out[col] = df[col]\n",
    "        else:\n",
    "            df_out[col] = \"\"\n",
    "\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean each Team Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the column order\n",
    "STUDY = reorder_table_to_CDE(STUDY, \"STUDY\", CDE)\n",
    "SAMPLE = reorder_table_to_CDE(SAMPLE, \"SAMPLE\", CDE)\n",
    "PROTOCOL = reorder_table_to_CDE(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "SUBJECT = reorder_table_to_CDE(SUBJECT, \"SUBJECT\", CDE)     \n",
    "CLINPATH = reorder_table_to_CDE(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "\n",
    "\n",
    "export_root = Path.cwd() / \"clean/team-Lee\"\n",
    "if not export_root.exists():\n",
    "    export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Hafler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the column order\n",
    "STUDY = reorder_table_to_CDE(STUDY, \"STUDY\", CDE)\n",
    "SAMPLE = reorder_table_to_CDE(SAMPLE, \"SAMPLE\", CDE)\n",
    "PROTOCOL = reorder_table_to_CDE(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "SUBJECT = reorder_table_to_CDE(SUBJECT, \"SUBJECT\", CDE)     \n",
    "CLINPATH = reorder_table_to_CDE(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "export_root = Path.cwd() / \"clean/team-Hafler\"\n",
    "if not export_root.exists():\n",
    "    export_root.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert \n",
    "data_path = Path.home() / (\"Projects/ASAP/team-hardy\")\n",
    "metadata_path = data_path / \"metadata\"\n",
    "\n",
    "SUBJECT = pd.read_csv(f\"{metadata_path}/SUBJECT.csv\")\n",
    "CLINPATH = pd.read_csv(f\"{metadata_path}/CLINPATH.csv\")\n",
    "STUDY = pd.read_csv(f\"{metadata_path}/STUDY.csv\")\n",
    "PROTOCOL = pd.read_csv(f\"{metadata_path}/PROTOCOL.csv\")\n",
    "SAMPLE = pd.read_csv(f\"{metadata_path}/SAMPLE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMissing Required Fields in STUDY: project_name, project_dataset, project_description, ASAP_team_name, ASAP_lab_name, PI_full_name, PI_email, contributor_names, submitter_name, submittor_email, ASAP_grant_id, other_funding_source, publication_DOI, publication_PMID, number_of_brain_samples, brain_regions, types_of_samples, DUA_version\n",
      "No empty or NaN values found in Required fields.\n",
      "No empty or NaN values found in Optional fields.\n",
      "\tAll Enum fields have valid values in STUDY.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project_description</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Ryten Lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PI_full_name</td>\n",
       "      <td>Mina Ryten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PI_email</td>\n",
       "      <td>mina.ryten@ucl.ac.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contributor_names</td>\n",
       "      <td>Aine Fairbrother-Browne, Jonathan Brenton, Mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>submitter_name</td>\n",
       "      <td>Aine Fairbrother-Browne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>submitter_email</td>\n",
       "      <td>aine.fairbrother-browne.18@ucl.ac.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASAP_grant_id</td>\n",
       "      <td>ASAP-000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>other_funding_source</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>publication_DOI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>publication_PMID</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>number_of_brain_samples</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>brain_regions</td>\n",
       "      <td>Inferior Parietal Lobule (IPL), Anterior Cingu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>types_of_samples</td>\n",
       "      <td>Late stage (Braak 5-6) PD and control post-mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PI_ORCHID</td>\n",
       "      <td>0000-0001-9520-6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PI_google_scholar_id</td>\n",
       "      <td>https://scholar.google.co.uk/citations?user=lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DUA_version</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>metadata_version_date</td>\n",
       "      <td>Version 1, 09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                                              value\n",
       "0              project_name  Understanding mechanisms of Parkinson's diseas...\n",
       "1           project_dataset                                    Hardy snRNA-seq\n",
       "2       project_description  Genetic analysis has identified many risk gene...\n",
       "3            ASAP_team_name                                         TEAM-HARDY\n",
       "4             ASAP_lab_name                                          Ryten Lab\n",
       "5              PI_full_name                                         Mina Ryten\n",
       "6                  PI_email                               mina.ryten@ucl.ac.uk\n",
       "7         contributor_names  Aine Fairbrother-Browne, Jonathan Brenton, Mel...\n",
       "8            submitter_name                            Aine Fairbrother-Browne\n",
       "9           submitter_email               aine.fairbrother-browne.18@ucl.ac.uk\n",
       "10            ASAP_grant_id                                        ASAP-000478\n",
       "11     other_funding_source                                                NaN\n",
       "12          publication_DOI                                                NaN\n",
       "13         publication_PMID                                                NaN\n",
       "14  number_of_brain_samples                                                128\n",
       "15            brain_regions  Inferior Parietal Lobule (IPL), Anterior Cingu...\n",
       "16         types_of_samples  Late stage (Braak 5-6) PD and control post-mor...\n",
       "17                PI_ORCHID                                0000-0001-9520-6957\n",
       "18     PI_google_scholar_id  https://scholar.google.co.uk/citations?user=lt...\n",
       "19              DUA_version                                                NaN\n",
       "20    metadata_version_date                                 Version 1, 09/2023"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n",
    "STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>source_subject_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>replicate</th>\n",
       "      <th>replicate_count</th>\n",
       "      <th>repeated_sample</th>\n",
       "      <th>batch</th>\n",
       "      <th>tissue</th>\n",
       "      <th>brain_region</th>\n",
       "      <th>source_RIN</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_ontology_term_id</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>DV2000</th>\n",
       "      <th>pm_PH</th>\n",
       "      <th>donor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>babom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>babom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>babom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>babom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babom_ACG</td>\n",
       "      <td>P2/14</td>\n",
       "      <td>babom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>brain</td>\n",
       "      <td>ACG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0009835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>zupam_IPL</td>\n",
       "      <td>P78/11</td>\n",
       "      <td>zupam</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>zupam_IPL</td>\n",
       "      <td>P78/11</td>\n",
       "      <td>zupam</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>zupam_IPL</td>\n",
       "      <td>P78/11</td>\n",
       "      <td>zupam</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>zupam_IPL</td>\n",
       "      <td>P78/11</td>\n",
       "      <td>zupam</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>zupam_IPL</td>\n",
       "      <td>P78/11</td>\n",
       "      <td>zupam</td>\n",
       "      <td>rep2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>brain</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>PATO:0000383 (female)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0006088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EFO:0008913</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3616 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id source_subject_id subject_id replicate  replicate_count   \n",
       "0     babom_ACG             P2/14      babom       NaN                1  \\\n",
       "1     babom_ACG             P2/14      babom       NaN                1   \n",
       "2     babom_ACG             P2/14      babom       NaN                1   \n",
       "3     babom_ACG             P2/14      babom       NaN                1   \n",
       "4     babom_ACG             P2/14      babom       NaN                1   \n",
       "...         ...               ...        ...       ...              ...   \n",
       "3611  zupam_IPL            P78/11      zupam      rep2                2   \n",
       "3612  zupam_IPL            P78/11      zupam      rep2                2   \n",
       "3613  zupam_IPL            P78/11      zupam      rep2                2   \n",
       "3614  zupam_IPL            P78/11      zupam      rep2                2   \n",
       "3615  zupam_IPL            P78/11      zupam      rep2                2   \n",
       "\n",
       "      repeated_sample batch tissue brain_region  source_RIN  ...   \n",
       "0                   0    B1  brain          ACG         NaN  ...  \\\n",
       "1                   0    B1  brain          ACG         NaN  ...   \n",
       "2                   0    B1  brain          ACG         NaN  ...   \n",
       "3                   0    B1  brain          ACG         NaN  ...   \n",
       "4                   0    B1  brain          ACG         NaN  ...   \n",
       "...               ...   ...    ...          ...         ...  ...   \n",
       "3611                1    B2  brain          IPL         NaN  ...   \n",
       "3612                1    B2  brain          IPL         NaN  ...   \n",
       "3613                1    B2  brain          IPL         NaN  ...   \n",
       "3614                1    B2  brain          IPL         NaN  ...   \n",
       "3615                1    B2  brain          IPL         NaN  ...   \n",
       "\n",
       "       sex_ontology_term_id self_reported_ethnicity_ontology_term_id   \n",
       "0     PATO:0000383 (female)                                      NaN  \\\n",
       "1     PATO:0000383 (female)                                      NaN   \n",
       "2     PATO:0000383 (female)                                      NaN   \n",
       "3     PATO:0000383 (female)                                      NaN   \n",
       "4     PATO:0000383 (female)                                      NaN   \n",
       "...                     ...                                      ...   \n",
       "3611  PATO:0000383 (female)                                      NaN   \n",
       "3612  PATO:0000383 (female)                                      NaN   \n",
       "3613  PATO:0000383 (female)                                      NaN   \n",
       "3614  PATO:0000383 (female)                                      NaN   \n",
       "3615  PATO:0000383 (female)                                      NaN   \n",
       "\n",
       "      disease_ontology_term_id tissue_ontology_term_id   \n",
       "0                MONDO:0005180          UBERON:0009835  \\\n",
       "1                MONDO:0005180          UBERON:0009835   \n",
       "2                MONDO:0005180          UBERON:0009835   \n",
       "3                MONDO:0005180          UBERON:0009835   \n",
       "4                MONDO:0005180          UBERON:0009835   \n",
       "...                        ...                     ...   \n",
       "3611             MONDO:0005180          UBERON:0006088   \n",
       "3612             MONDO:0005180          UBERON:0006088   \n",
       "3613             MONDO:0005180          UBERON:0006088   \n",
       "3614             MONDO:0005180          UBERON:0006088   \n",
       "3615             MONDO:0005180          UBERON:0006088   \n",
       "\n",
       "     cell_type_ontology_term_id  assay_ontology_term_id suspension_type   \n",
       "0                           NaN             EFO:0008913         nucleus  \\\n",
       "1                           NaN             EFO:0008913         nucleus   \n",
       "2                           NaN             EFO:0008913         nucleus   \n",
       "3                           NaN             EFO:0008913         nucleus   \n",
       "4                           NaN             EFO:0008913         nucleus   \n",
       "...                         ...                     ...             ...   \n",
       "3611                        NaN             EFO:0008913         nucleus   \n",
       "3612                        NaN             EFO:0008913         nucleus   \n",
       "3613                        NaN             EFO:0008913         nucleus   \n",
       "3614                        NaN             EFO:0008913         nucleus   \n",
       "3615                        NaN             EFO:0008913         nucleus   \n",
       "\n",
       "     DV2000 pm_PH donor_id  \n",
       "0       NaN   NaN      NaN  \n",
       "1       NaN   NaN      NaN  \n",
       "2       NaN   NaN      NaN  \n",
       "3       NaN   NaN      NaN  \n",
       "4       NaN   NaN      NaN  \n",
       "...     ...   ...      ...  \n",
       "3611    NaN   NaN      NaN  \n",
       "3612    NaN   NaN      NaN  \n",
       "3613    NaN   NaN      NaN  \n",
       "3614    NaN   NaN      NaN  \n",
       "3615    NaN   NaN      NaN  \n",
       "\n",
       "[3616 rows x 42 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there seems to be something funky with SAMPLE\n",
    "# SAMPLE = SAMPLE[SAMPLE[\"batch\"]==\"B1\"]\n",
    "# SAMPLE.drop_duplicates(inplace=True) #, subset=[ \"file_name\"])\n",
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project_description</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Ryten Lab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                              value\n",
       "0         project_name  Understanding mechanisms of Parkinson's diseas...\n",
       "1      project_dataset                                    Hardy snRNA-seq\n",
       "2  project_description  Genetic analysis has identified many risk gene...\n",
       "3       ASAP_team_name                                         TEAM-HARDY\n",
       "4        ASAP_lab_name                                          Ryten Lab"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STUDY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>project_description</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>PI_full_name</td>\n",
       "      <td>PI_email</td>\n",
       "      <td>contributor_names</td>\n",
       "      <td>submitter_name</td>\n",
       "      <td>submitter_email</td>\n",
       "      <td>...</td>\n",
       "      <td>other_funding_source</td>\n",
       "      <td>publication_DOI</td>\n",
       "      <td>publication_PMID</td>\n",
       "      <td>number_of_brain_samples</td>\n",
       "      <td>brain_regions</td>\n",
       "      <td>types_of_samples</td>\n",
       "      <td>PI_ORCHID</td>\n",
       "      <td>PI_google_scholar_id</td>\n",
       "      <td>DUA_version</td>\n",
       "      <td>metadata_version_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "      <td>Ryten Lab</td>\n",
       "      <td>Mina Ryten</td>\n",
       "      <td>mina.ryten@ucl.ac.uk</td>\n",
       "      <td>Aine Fairbrother-Browne, Jonathan Brenton, Mel...</td>\n",
       "      <td>Aine Fairbrother-Browne</td>\n",
       "      <td>aine.fairbrother-browne.18@ucl.ac.uk</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>Inferior Parietal Lobule (IPL), Anterior Cingu...</td>\n",
       "      <td>Late stage (Braak 5-6) PD and control post-mor...</td>\n",
       "      <td>0000-0001-9520-6957</td>\n",
       "      <td>https://scholar.google.co.uk/citations?user=lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Version 1, 09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0                1    \n",
       "0                                       project_name  project_dataset  \\\n",
       "1  Understanding mechanisms of Parkinson's diseas...  Hardy snRNA-seq   \n",
       "\n",
       "                                                  2               3    \n",
       "0                                project_description  ASAP_team_name  \\\n",
       "1  Genetic analysis has identified many risk gene...      TEAM-HARDY   \n",
       "\n",
       "              4             5                     6    \n",
       "0  ASAP_lab_name  PI_full_name              PI_email  \\\n",
       "1      Ryten Lab    Mina Ryten  mina.ryten@ucl.ac.uk   \n",
       "\n",
       "                                                  7                        8    \n",
       "0                                  contributor_names           submitter_name  \\\n",
       "1  Aine Fairbrother-Browne, Jonathan Brenton, Mel...  Aine Fairbrother-Browne   \n",
       "\n",
       "                                     9   ...                    11   \n",
       "0                       submitter_email  ...  other_funding_source  \\\n",
       "1  aine.fairbrother-browne.18@ucl.ac.uk  ...                   NaN   \n",
       "\n",
       "                12                13                       14   \n",
       "0  publication_DOI  publication_PMID  number_of_brain_samples  \\\n",
       "1              NaN               NaN                      128   \n",
       "\n",
       "                                                  15   \n",
       "0                                      brain_regions  \\\n",
       "1  Inferior Parietal Lobule (IPL), Anterior Cingu...   \n",
       "\n",
       "                                                  16                   17   \n",
       "0                                   types_of_samples            PI_ORCHID  \\\n",
       "1  Late stage (Braak 5-6) PD and control post-mor...  0000-0001-9520-6957   \n",
       "\n",
       "                                                  18           19   \n",
       "0                               PI_google_scholar_id  DUA_version  \\\n",
       "1  https://scholar.google.co.uk/citations?user=lt...          NaN   \n",
       "\n",
       "                      20  \n",
       "0  metadata_version_date  \n",
       "1     Version 1, 09/2023  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fix STUDY formatting\n",
    "tmp = pd.DataFrame()\n",
    "tmp = STUDY[[\"name\",\"value\"]].transpose().reset_index().drop(columns=[\"index\"])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_dataset</th>\n",
       "      <th>project_description</th>\n",
       "      <th>ASAP_team_name</th>\n",
       "      <th>ASAP_lab_name</th>\n",
       "      <th>PI_full_name</th>\n",
       "      <th>PI_email</th>\n",
       "      <th>contributor_names</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submitter_email</th>\n",
       "      <th>...</th>\n",
       "      <th>other_funding_source</th>\n",
       "      <th>publication_DOI</th>\n",
       "      <th>publication_PMID</th>\n",
       "      <th>number_of_brain_samples</th>\n",
       "      <th>brain_regions</th>\n",
       "      <th>types_of_samples</th>\n",
       "      <th>PI_ORCHID</th>\n",
       "      <th>PI_google_scholar_id</th>\n",
       "      <th>DUA_version</th>\n",
       "      <th>metadata_version_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "      <td>Ryten Lab</td>\n",
       "      <td>Mina Ryten</td>\n",
       "      <td>mina.ryten@ucl.ac.uk</td>\n",
       "      <td>Aine Fairbrother-Browne, Jonathan Brenton, Mel...</td>\n",
       "      <td>Aine Fairbrother-Browne</td>\n",
       "      <td>aine.fairbrother-browne.18@ucl.ac.uk</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>Inferior Parietal Lobule (IPL), Anterior Cingu...</td>\n",
       "      <td>Late stage (Braak 5-6) PD and control post-mor...</td>\n",
       "      <td>0000-0001-9520-6957</td>\n",
       "      <td>https://scholar.google.co.uk/citations?user=lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Version 1, 09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                       project_name  project_dataset   \n",
       "1  Understanding mechanisms of Parkinson's diseas...  Hardy snRNA-seq  \\\n",
       "\n",
       "0                                project_description ASAP_team_name   \n",
       "1  Genetic analysis has identified many risk gene...     TEAM-HARDY  \\\n",
       "\n",
       "0 ASAP_lab_name PI_full_name              PI_email   \n",
       "1     Ryten Lab   Mina Ryten  mina.ryten@ucl.ac.uk  \\\n",
       "\n",
       "0                                  contributor_names           submitter_name   \n",
       "1  Aine Fairbrother-Browne, Jonathan Brenton, Mel...  Aine Fairbrother-Browne  \\\n",
       "\n",
       "0                       submitter_email  ... other_funding_source   \n",
       "1  aine.fairbrother-browne.18@ucl.ac.uk  ...                  NaN  \\\n",
       "\n",
       "0 publication_DOI publication_PMID number_of_brain_samples   \n",
       "1             NaN              NaN                     128  \\\n",
       "\n",
       "0                                      brain_regions   \n",
       "1  Inferior Parietal Lobule (IPL), Anterior Cingu...  \\\n",
       "\n",
       "0                                   types_of_samples            PI_ORCHID   \n",
       "1  Late stage (Braak 5-6) PD and control post-mor...  0000-0001-9520-6957  \\\n",
       "\n",
       "0                               PI_google_scholar_id DUA_version   \n",
       "1  https://scholar.google.co.uk/citations?user=lt...         NaN  \\\n",
       "\n",
       "0 metadata_version_date  \n",
       "1    Version 1, 09/2023  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp.columns = tmp.iloc[0]\n",
    "STUDY = tmp.drop([0])\n",
    "STUDY.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in STUDY.\n",
      "No empty or NaN values found in Required fields.\n",
      "No empty or NaN values found in Optional fields.\n",
      "\tAll Enum fields have valid values in STUDY.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fix the column order\n",
    "STUDY = reorder_table_to_CDE(STUDY, \"STUDY\", CDE)\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_collection_summary</td>\n",
       "      <td>This dataset contains cortical regions only, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell_extraction_summary</td>\n",
       "      <td>From protocols.io: This protocol is used to is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lib_prep_summary</td>\n",
       "      <td>'Nuclei were extracted from homogenised post-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_processing_summary</td>\n",
       "      <td>Cell ranger was used to convert raw sequencing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>github_url</td>\n",
       "      <td>Raw to fastq to mapped: https://github.com/RHR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name   \n",
       "0  sample_collection_summary  \\\n",
       "1    cell_extraction_summary   \n",
       "2           lib_prep_summary   \n",
       "3    data_processing_summary   \n",
       "4                 github_url   \n",
       "\n",
       "                                               value  \n",
       "0  This dataset contains cortical regions only, p...  \n",
       "1  From protocols.io: This protocol is used to is...  \n",
       "2  'Nuclei were extracted from homogenised post-m...  \n",
       "3  Cell ranger was used to convert raw sequencing...  \n",
       "4  Raw to fastq to mapped: https://github.com/RHR...  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROTOCOL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_collection_summary</th>\n",
       "      <th>cell_extraction_summary</th>\n",
       "      <th>lib_prep_summary</th>\n",
       "      <th>data_processing_summary</th>\n",
       "      <th>github_url</th>\n",
       "      <th>protocols_io_DOI</th>\n",
       "      <th>other_reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This dataset contains cortical regions only, p...</td>\n",
       "      <td>From protocols.io: This protocol is used to is...</td>\n",
       "      <td>'Nuclei were extracted from homogenised post-m...</td>\n",
       "      <td>Cell ranger was used to convert raw sequencing...</td>\n",
       "      <td>Raw to fastq to mapped: https://github.com/RHR...</td>\n",
       "      <td>Nuclear extraction protocol: 10.17504/protocol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                          sample_collection_summary   \n",
       "1  This dataset contains cortical regions only, p...  \\\n",
       "\n",
       "0                            cell_extraction_summary   \n",
       "1  From protocols.io: This protocol is used to is...  \\\n",
       "\n",
       "0                                   lib_prep_summary   \n",
       "1  'Nuclei were extracted from homogenised post-m...  \\\n",
       "\n",
       "0                            data_processing_summary   \n",
       "1  Cell ranger was used to convert raw sequencing...  \\\n",
       "\n",
       "0                                         github_url   \n",
       "1  Raw to fastq to mapped: https://github.com/RHR...  \\\n",
       "\n",
       "0                                   protocols_io_DOI other_reference  \n",
       "1  Nuclear extraction protocol: 10.17504/protocol...             NaN  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix STUDY formatting\n",
    "tmp = pd.DataFrame()\n",
    "tmp = PROTOCOL[[\"name\",\"value\"]].transpose().reset_index().drop(columns=[\"index\"])\n",
    "tmp.columns = tmp.iloc[0]\n",
    "PROTOCOL = tmp.drop([0])\n",
    "PROTOCOL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in PROTOCOL.\n",
      "No empty or NaN values found in Required fields.\n",
      "No empty or NaN values found in Optional fields.\n",
      "\tAll Enum fields have valid values in PROTOCOL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the column order\n",
    "PROTOCOL = reorder_table_to_CDE(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "validate_table(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in SUBJECT.\n",
      "\t\tRequired Fields with Empty or NaN values:\n",
      "\t\t\t- ethnicity: 64 rows\n",
      "\t\t\t- duration_pmi: 1 rows\n",
      "No empty or NaN values found in Optional fields.\n",
      "\tInvalid Field/Value pairs:\n",
      "\t\t\t- race: Nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SUBJECT = reorder_table_to_CDE(SUBJECT, \"SUBJECT\", CDE)\n",
    "\n",
    "# Testing the function with SUBJECT.csv and CDE.csv\n",
    "validate_table(SUBJECT, \"SUBJECT\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT.replace(\"Nan\", \"\", inplace=True)\n",
    "SUBJECT.replace(\"nan\", \"\", inplace=True)\n",
    "SUBJECT.fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in SAMPLE.\n",
      "\t\tRequired Fields with Empty or NaN values:\n",
      "\t\t\t- source_RIN: 3616 rows\n",
      "\t\tOptional Fields with Empty or NaN values:\n",
      "\t\t\t- pm_PH: 3616 rows\n",
      "\tInvalid Field/Value pairs:\n",
      "\t\t\t- sequencing_length: 190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE = reorder_table_to_CDE(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "# force the right sex_ontology_term_id\n",
    "SAMPLE[\"organism_ontology_term_id\"] = \"NCBITaxon:9606\"\n",
    "\n",
    "# allos sequence_length == 190 for now\n",
    "validate_table(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "\n",
    "# add 'replicate' coding (nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE.replace(\"nan\", \"\", inplace=True)\n",
    "# sequence length will need to be converted to a string\n",
    "SAMPLE.fillna(\"\", inplace=True)\n",
    "# Testing the function with SAMPLE.csv and CDE.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in CLINPATH.\n",
      "\t\tRequired Fields with Empty or NaN values:\n",
      "\t\t\t- age_at_onset: 138 rows\n",
      "\t\t\t- age_at_diagnosis: 10 rows\n",
      "\t\t\t- first_motor_symptom: 138 rows\n",
      "\t\t\t- path_year_death: 138 rows\n",
      "\t\t\t- brain_weight: 138 rows\n",
      "\t\tOptional Fields with Empty or NaN values:\n",
      "\t\t\t- smoking_years: 138 rows\n",
      "\tInvalid Field/Value pairs:\n",
      "\t\t\t- family_history: Nan\n",
      "\t\t\t- hx_dementia_mci: Nan\n",
      "\t\t\t- hx_melanoma: Nan\n",
      "\t\t\t- education_level: Nan\n",
      "\t\t\t- smoking_status: Nan\n",
      "\t\t\t- APOE_e4_status: Nan\n",
      "\t\t\t- cognitive_status: Nan\n",
      "\t\t\t- path_autopsy_dx_main: Control brain, Pathological ageing, Control brain / Path ageing, Argyrophilic grain disease, Control brain, Cerebrovascular disease (small vessel), Cerebrovascular disease (small vessel), Control brain, Alzheimer`s disease (intermediate level AD pathological change), Control brain / Path ageing, CAA, Nan\n",
      "\t\t\t- path_braak_nft: 2.0, 1.0, 3.0, 0.0, 4.0, 6.0, Nan\n",
      "\t\t\t- path_braak_asyn: 6.0, 0.0, 5.0, Nan\n",
      "\t\t\t- path_cerad: Nan\n",
      "\t\t\t- path_thal: At least 4, Nan\n",
      "\t\t\t- known_pathogenic_mutation: Nan\n",
      "\t\t\t- path_mckeith: Diffuse neocortical, Limbic transitional, Diffuse Neocortical, Nan\n",
      "\t\t\t- sn_neuronal_loss: Nan\n",
      "\t\t\t- path_infarcs: Nan\n",
      "\t\t\t- path_nia_ri: Nan\n",
      "\t\t\t- path_nia_aa_a: 1.0, 2.0, 0.0, 3.0, Nan\n",
      "\t\t\t- path_nia_aa_b: 1.0, 2.0, 0.0, 3.0, Nan\n",
      "\t\t\t- path_nia_aa_c: 0.0, 1.0, 2.0, 3.0, Nan\n",
      "\t\t\t- TDP43: Nan\n",
      "\t\t\t- arteriolosclerosis_severity_scale: Nan\n",
      "\t\t\t- amyloid_angiopathy_severity_scale: Nan\n",
      "\t\t\t- path_ad_level: Nan, No evidence\n",
      "\t\t\t- dig_slide_avail: Yes\n",
      "\t\t\t- quant_path_avail: Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLINPATH = reorder_table_to_CDE(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "\n",
    "# Testing the function with CLINPATH.csv and CDE.csv\n",
    "validate_table(CLINPATH, \"CLINPATH\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to make sure the replace below works.\n",
    "CLINPATH.replace(\"\", pd.NA, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'path_braak_asyn' with with string of the numeric. converte nan to \"\"\n",
    "CLINPATH['path_braak_asyn'] = CLINPATH['path_braak_asyn'].apply(lambda val: str(int(val)) if pd.notna(val) else \"\")\n",
    "\n",
    "# replace 'path_braak_nft' with with string of the numeric. converte nan to \"\"\n",
    "CLINPATH['path_braak_nft'] = CLINPATH['path_braak_nft'].apply(lambda val: str(int(val)) if pd.notna(val) else \"\").replace({\"0\":\"0\", \n",
    "                                                                                                                           \"1\":\"I\", \n",
    "                                                                                                                           \"2\": \"II\", \n",
    "                                                                                                                           \"3\":\"III\", \n",
    "                                                                                                                           \"4\":\"IV\", \n",
    "                                                                                                                           \"5\":\"V\", \n",
    "                                                                                                                           \"6\":\"VI\"})\n",
    "\n",
    "# code family_history as \"Not Reported\" (currently empty)\n",
    "CLINPATH['family_history'] = \"Not Reported\"\n",
    "\n",
    "\n",
    "\n",
    "# check APOE_e4_status ? currently empty\n",
    "\n",
    "# `path_autopsy_dx_main`  actually seems good parser might be wrong\n",
    "\n",
    "# code \"at least 4\" as \"4/5\" \n",
    "\n",
    "CLINPATH['path_thal'] = CLINPATH['path_thal'].replace({'At least 4':\"4/5\"})\n",
    "\n",
    "\n",
    "CLINPATH['path_mckeith'] = CLINPATH['path_mckeith'].replace({'Diffuse neocortical': \"Diffuse, neocortical (brainstem, limbic and neocortical involvement)\", \n",
    "                                                        'Limbic transitional': \"Limbic (transitional)\" ,\n",
    "                                                        'Diffuse Neocortical':\"Diffuse, neocortical (brainstem, limbic and neocortical involvement)\"})\n",
    "\n",
    "# replace 'path_braak_nft' with with string of the numeric. converte nan to \"\"\n",
    "CLINPATH['path_nia_aa_a'] = CLINPATH['path_nia_aa_a'].apply(lambda val: str(int(val)) if pd.notna(val) else \"\")\n",
    "\n",
    "CLINPATH['path_nia_aa_a'] = CLINPATH['path_nia_aa_a'].replace({\"0\":\"A0\", \n",
    "                                                                                                                           \"1\":\"A1\", \n",
    "                                                                                                                           \"2\": \"A2\", \n",
    "                                                                                                                           \"3\":\"A3\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace 'path_braak_nft' with with string of the numeric. converte nan to \"\"\n",
    "CLINPATH['path_nia_aa_b'] = CLINPATH['path_nia_aa_b'].apply(lambda val: str(int(val)) if pd.notna(val) else \"\").replace({\"0\":\"B0\", \n",
    "                                                                                                                           \"1\":\"B1\", \n",
    "                                                                                                                           \"2\": \"B2\", \n",
    "                                                                                                                           \"3\":\"B3\"})\n",
    "\n",
    "\n",
    "# replace 'path_braak_nft' with with string of the numeric. converte nan to \"\"\n",
    "CLINPATH['path_nia_aa_c'] = CLINPATH['path_nia_aa_c'].apply(lambda val: str(int(val)) if pd.notna(val) else \"\").replace({\"0\":\"C0\", \n",
    "                                                                                                                           \"1\":\"C1\", \n",
    "                                                                                                                           \"2\": \"C2\", \n",
    "                                                                                                                           \"3\":\"C3\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "CLINPATH['path_ad_level'] = CLINPATH['path_ad_level'].replace({\"No evidence\": \"No evidence of Alzheimer\\'s disease neuropathological change\"})\n",
    "\n",
    "\n",
    "# empty 'hx_dementia_mci', 'hx_melanoma', 'education_level', 'cognitive_status'\n",
    "#  coded as nan will be fixed with .fillna(\"\") below\n",
    "CLINPATH.replace(\"nan\", \"\", inplace=True)\n",
    "CLINPATH.fillna(\"\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['[\"Yes, No\"]'], dtype=object), array(['Yes'], dtype=object))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDE[CDE[\"Field\"]==\"dig_slide_avail\"].Validation.unique(), CLINPATH['dig_slide_avail'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAll required fields are present in CLINPATH.\n",
      "No empty or NaN values found in Required fields.\n",
      "No empty or NaN values found in Optional fields.\n",
      "\tInvalid Field/Value pairs:\n",
      "\t\t\t- path_autopsy_dx_main: Control brain, Pathological ageing, Control brain / Path ageing, Argyrophilic grain disease, Control brain, Cerebrovascular disease (small vessel), Cerebrovascular disease (small vessel), Control brain, Alzheimer`s disease (intermediate level AD pathological change), Control brain / Path ageing, CAA, \n",
      "\t\t\t- path_nia_aa_a: A0, \n",
      "\t\t\t- path_nia_aa_b: B0, \n",
      "\t\t\t- path_nia_aa_c: C0, \n",
      "\t\t\t- dig_slide_avail: Yes\n",
      "\t\t\t- quant_path_avail: Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function with CLINPATH.csv and CDE.csv\n",
    "validate_table(CLINPATH, \"CLINPATH\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # write the clean metadata\n",
    "# STUDY.to_csv(data_path / \"metadata/STUDY.csv\")\n",
    "# PROTOCOL.to_csv(data_path / \"metadata/PROTOCOL.csv\")\n",
    "# CLINPATH.to_csv(data_path / \"metadata/CLINPATH.csv\")\n",
    "# SAMPLE.to_csv(data_path / \"metadata/SAMPLE.csv\")\n",
    "# SUBJECT.to_csv(data_path / \"metadata/SUBJECT.csv\")\n",
    "\n",
    "# # also writh them to clean...\n",
    "# \n",
    "#  \n",
    "\n",
    "export_root = Path.cwd() / \"clean/team-Hardy\"\n",
    "if not export_root.exists():\n",
    "    export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "STUDY.to_csv( export_root / \"STUDY.csv\")\n",
    "PROTOCOL.to_csv(export_root / \"PROTOCOL.csv\")\n",
    "SAMPLE.to_csv(export_root / \"SAMPLE.csv\")\n",
    "SUBJECT.to_csv(export_root / \"SUBJECT.csv\")\n",
    "CLINPATH.to_csv(export_root / \"CLINPATH.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically hold the list of the GP2ID and the original clinical ID pairs + how many samples are in the GP2 (s1 only or s1, s2,...) for all GP2 submitted individuals. It takes the sample manifest, scan the clinical ID to check if this is the additional submission of those already in the GP2 or not and then if its new, give new GP2ID and GP2sampleID. If the clinical_id is already existing in the GP2 then only provide GP2sampleID (GP2ID_sX+1). Also it errors if the original sample ID submitted is equal to the one in the list. (No duplication of sample ID from the same cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names = [\"team-lee\", \"team-hafler\", \"team-hardy\", \"team-jakobsson\", \"team-sherzer\",\"team-sulzer\", \"tam-voet\",\"team-wood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_code = [\"LEE\", \"HAF\", \"HAR\", \"JAK\", \"SHE\", \"SUL\", \"VOE\", \"WOO\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEAM-LEE',\n",
       " 'TEAM-HAFLER',\n",
       " 'TEAM-HARDY',\n",
       " 'TEAM-JAKOBSSON',\n",
       " 'TEAM-SHERZER',\n",
       " 'TEAM-SULZER',\n",
       " 'TAM-VOET',\n",
       " 'TEAM-WOOD']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.upper() for x in team_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    uids = [str(id) for id in df_nodups['sample_id'].unique()]\n",
    "    mapid = {}\n",
    "    for uid in uids:\n",
    "        mapid[uid]= n\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getgp2idsv2(dfproc, n, study_code):\n",
    "    df_dups = dfproc[dfproc.duplicated(keep=False, subset=['clinical_id'])].sort_values('clinical_id').reset_index(drop = True).copy()\n",
    "    if df_dups.shape[0]>0:\n",
    "        dupids_mapper = dict(zip(df_dups.clinical_id.unique(),\n",
    "                            [num+n for num in range(len(df_dups.clinical_id.unique()))]))\n",
    "        \n",
    "        df_dup_chunks = []\n",
    "        for clin_id, gp2id in dupids_mapper.items():\n",
    "            df_dups_subset = df_dups[df_dups.clinical_id==clin_id].copy()\n",
    "            df_dups_subset['GP2ID'] = [f'{study_code}_{gp2id:06}' for i in range(df_dups_subset.shape[0])]\n",
    "            df_dups_subset['SampleRepNo'] = ['s'+str(i+1) for i in range(df_dups_subset.shape[0])]\n",
    "            df_dups_subset['GP2sampleID'] = df_dups_subset['GP2ID'] + '_' + df_dups_subset['SampleRepNo']\n",
    "            df_dup_chunks.append(df_dups_subset)\n",
    "        df_dups_wids = pd.concat(df_dup_chunks)\n",
    "\n",
    "    df_nodups = dfproc[~dfproc.duplicated(keep=False, subset=['clinical_id'])].sort_values('clinical_id').reset_index(drop = True).copy()\n",
    "\n",
    "    if df_dups.shape[0]>0:\n",
    "        n =  len(list(dupids_mapper.values())) + n\n",
    "    else:\n",
    "        n = n\n",
    "\n",
    "    uids = [str(id) for id in df_nodups['sample_id'].unique()]\n",
    "    mapid = {}\n",
    "    for uid in uids:\n",
    "        mapid[uid]= n\n",
    "        n += 1\n",
    "    df_nodups_wids = df_nodups.copy()\n",
    "    df_nodups_wids['uid_idx'] = df_nodups_wids['sample_id'].map(mapid)\n",
    "    df_nodups_wids['GP2ID'] = [f'{study_code}_{i:06}' for i in df_nodups_wids.uid_idx]\n",
    "    df_nodups_wids['uid_idx_cumcount'] = df_nodups_wids.groupby('GP2ID').cumcount() + 1\n",
    "    df_nodups_wids['GP2sampleID'] = df_nodups_wids.GP2ID + '_s' + df_nodups_wids.uid_idx_cumcount.astype('str')\n",
    "    df_nodups_wids['SampleRepNo'] = 's' + df_nodups_wids.uid_idx_cumcount.astype('str')\n",
    "    df_nodups_wids.drop(['uid_idx','uid_idx_cumcount'], axis = 1, inplace = True)\n",
    "\n",
    "    if df_dups.shape[0]>0:\n",
    "        df_newids = pd.concat([df_dups_wids, df_nodups_wids])\n",
    "    else:\n",
    "        df_newids = df_nodups_wids\n",
    "    \n",
    "    return(df_newids)\n",
    "\n",
    "def assign_unique_gp2clinicalids(df, clinicalid_subset):\n",
    "\n",
    "    if isinstance(clinicalid_subset, pd.Series):\n",
    "        clinicalid_subset = clinicalid_subset.to_frame().T\n",
    "\n",
    "    sampleid = clinicalid_subset.sort_values(by=['master_GP2sampleID'])\\\n",
    "                                .reset_index(drop = True)\\\n",
    "                                .dropna(subset=['master_GP2sampleID'], axis = 0)\n",
    "    sampleid = sampleid.loc[sampleid.index[-1], 'master_GP2sampleID'].split(\"_\")\n",
    "    getuniqueid = sampleid[0] + \"_\" + sampleid[1]\n",
    "    get_sidrepno = int(sampleid[2].replace(\"s\",\"\")) + 1\n",
    "\n",
    "    index_modify = clinicalid_subset['index'].unique() #clinicalid_subset[clinicalid_subset['GP2sampleID'].isnull()] #.index\n",
    "    assign_gp2sampleid = [getuniqueid + \"_s\" + str(get_sidrepno + i) for i in range(len(index_modify))]\n",
    "    df.loc[index_modify, 'GP2sampleID'] = assign_gp2sampleid\n",
    "    getnewidrows = df.loc[index_modify].copy()\n",
    "    return (getnewidrows)\n",
    "\n",
    "def master_keyv2(studies):\n",
    "    # ACCESS MASTERGP2IDS_JSON IN GP2 BUCKET\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket('eu-samplemanifest')\n",
    "    blob = bucket.blob('IDSTRACKER/GP2IDSMAPPER.json')\n",
    "    \n",
    "    ids_tracker = {}\n",
    "    with blob.open(\"r\") as f:\n",
    "        for k, v in ijson.kvitems(f, ''):\n",
    "            if k in studies:\n",
    "                ids_tracker.update({k:v})\n",
    "    \n",
    "    return(ids_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'----------------------------------------'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40*\"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # GENERATE GP2 IDs #\n",
    "        jumptwice()\n",
    "        st.subheader('GP2 IDs assignment...')\n",
    "        studynames = list(df['study'].unique())\n",
    "\n",
    "        if st.session_state['master_get'] == None: # TO ONLY RUN ONCE\n",
    "            #ids_tracker = generategp2ids.master_key(studies = studynames)\n",
    "            ids_tracker = generategp2ids.master_keyv2(studies = studynames)\n",
    "            study_subsets = []\n",
    "            log_new = []\n",
    "            df['GP2sampleID'] = None\n",
    "            # GP2 ID ASSIGNMENT CODE BLOCK\n",
    "            for study in studynames:\n",
    "                st.write(f\"Getting GP2IDs for {study} samples\")\n",
    "                df_subset = df[df.study==study].copy()\n",
    "                try:\n",
    "                    #study_tracker = st.session_state['store_tracker'][study]\n",
    "                    study_tracker = ids_tracker[study]\n",
    "                    study_tracker_df = pd.DataFrame.from_dict(study_tracker,\n",
    "                                                            orient='index',\n",
    "                                                            columns = ['master_GP2sampleID','clinical_id'])\\\n",
    "                                                    .rename_axis('master_sample_id').reset_index()\\\n",
    "                                                    .astype(str)\n",
    "\n",
    "                    # Check if any sample ID exists in df_subset.\n",
    "                    sample_id_unique = pd.merge(study_tracker_df, df_subset,\n",
    "                                                left_on=['master_sample_id'], right_on=['sample_id'], how='inner')\n",
    "                    if not sample_id_unique.empty:\n",
    "                        st.error('We have detected sample ids submitted on previous versions')\n",
    "                        st.error('Please, correct these sample IDs so that they are unique and resubmit the sample manifest.')\n",
    "                        sample_id_unique = sample_id_unique.rename(columns={\"clinical_id_y\": \"clinical_id\"})\n",
    "                        st.dataframe(\n",
    "                        sample_id_unique[['study','sample_id','clinical_id']].style.set_properties(**{\"background-color\": \"brown\", \"color\": \"lawngreen\"})\n",
    "                        )\n",
    "                        stopapp=True\n",
    "                    else:\n",
    "                        stopapp=False\n",
    "                except:\n",
    "                    study_tracker = None\n",
    "                    stopapp = False\n",
    "                if stopapp:\n",
    "                    st.stop()\n",
    "\n",
    "                if bool(study_tracker):\n",
    "                    # WORK ON DUPLICATED IDS\n",
    "                    df_subset = df_subset.reset_index()\n",
    "                    data_duplicated = pd.merge(df_subset, study_tracker_df, on=['clinical_id'], how='inner')\n",
    "                    df_subset = df_subset.set_index('index')\n",
    "                    df_subset.index.name = None\n",
    "\n",
    "                    if data_duplicated.shape[0]>0:\n",
    "                        new_clinicaldups = True\n",
    "                        newids_clinicaldups = data_duplicated.groupby('clinical_id')\\\n",
    "                                                        .apply(lambda x: generategp2ids.assign_unique_gp2clinicalids(df_subset,x))\n",
    "\n",
    "                        if newids_clinicaldups.shape[0]>0:\n",
    "                            newids_clinicaldups = newids_clinicaldups.reset_index(drop=True)[['study','clinical_id','sample_id','GP2sampleID']]\n",
    "                            log_new.append(newids_clinicaldups)\n",
    "                    else:\n",
    "                        new_clinicaldups = False\n",
    "                        newids_clinicaldups = pd.DataFrame()\n",
    "\n",
    "                    # GET GP2 IDs METADATA for new CLINICAL-SAMPLE ID pairs\n",
    "                    df_newids = df_subset[df_subset['GP2sampleID'].isnull()].reset_index(drop = True).copy()\n",
    "                    if not df_newids.empty: # Get new GP2 IDs\n",
    "                        df_wids = df_subset[~df_subset['GP2sampleID'].isnull()].reset_index(drop = True).copy()\n",
    "                        df_wids['GP2ID'] = df_wids['GP2sampleID'].apply(lambda x: (\"_\").join(x.split(\"_\")[:-1]))\n",
    "                        df_wids['SampleRepNo'] = df_wids['GP2sampleID'].apply(lambda x: x.split(\"_\")[-1])#.replace(\"s\",\"\"))\n",
    "\n",
    "                        n=int(max(study_tracker_df['master_GP2sampleID'].to_list()).split(\"_\")[1])+1\n",
    "                        df_newids = generategp2ids.getgp2idsv2(df_newids, n, study)\n",
    "                        df_subset = pd.concat([df_newids, df_wids], axis = 0)\n",
    "                        study_subsets.append(df_subset)\n",
    "                        log_new.append(df_newids[['study','clinical_id','sample_id','GP2sampleID']])\n",
    "                        \n",
    "                    else: # TO CONSIDER THE CASE IN WHICH WE ONLY HAD DUPLICATE IDS MAPPED ON THE MASTER FILE\n",
    "                        df_subset['GP2ID'] = df_subset['GP2sampleID'].apply(lambda x: (\"_\").join(x.split(\"_\")[:-1]))\n",
    "                        df_subset['SampleRepNo'] = df_subset['GP2sampleID'].apply(lambda x: x.split(\"_\")[-1])#.replace(\"s\",\"\"))\n",
    "                        study_subsets.append(df_subset)\n",
    "\n",
    "                # Brand new data - NO STUDY TRACKER FOR THIS COHORT\n",
    "                else:\n",
    "                    study = study\n",
    "                    new_clinicaldups = False # Duplicates from master key json are treated differently to brand new data\n",
    "                    n = 1\n",
    "                    df_newids = generategp2ids.getgp2idsv2(df_subset, n, study)\n",
    "                    study_subsets.append(df_newids)\n",
    "\n",
    "\n",
    "                # CODE TO UPDATE THE GET FILE WE WILL USE TO UPDATE MASTER JSON\n",
    "                if (new_clinicaldups) and (newids_clinicaldups.shape[0]>0):\n",
    "                    tmp = pd.concat([df_newids[['study','clinical_id','sample_id','GP2sampleID']], newids_clinicaldups])\n",
    "                    tmp['master_value'] = list(zip(tmp['GP2sampleID'],\n",
    "                                                    tmp['clinical_id']))\n",
    "                    ids_log = tmp.groupby('study').apply(lambda x: dict(zip(x['sample_id'],\n",
    "                                                                            x['master_value']))).to_dict()\n",
    "                else:\n",
    "                    df_update_master = df_newids.copy()\n",
    "                    df_update_master['master_value'] = list(zip(df_update_master['GP2sampleID'],\n",
    "                                                            df_update_master['clinical_id']))\n",
    "                    ids_log = df_update_master.groupby('study').apply(lambda x: dict(zip(x['sample_id'],\n",
    "                                                                                    x['master_value']))).to_dict()\n",
    "\n",
    "                #generategp2ids.update_masterids(ids_log, study_tracker) # THIS WILL BE UPDATED ONCE THE USET CONFIRMS THE QC ( AT THE END)\n",
    "                \n",
    "                #if st.session_state['master_get'] == None:\n",
    "                if (isinstance(st.session_state['all_ids'], list)):\n",
    "                    st.session_state['all_ids'].append( [ids_log, study_tracker] )\n",
    "                if st.session_state['all_ids'] == None:\n",
    "                    st.session_state['all_ids'] = [ [ids_log, study_tracker] ]\n",
    "            \n",
    "\n",
    "            # OUT OF FOR LOOP // END OF GP2 IDS ASSIGNMENT. LET'S RESUME df.\n",
    "            df = pd.concat(study_subsets, axis = 0)\n",
    "            df = df[list(df)[-3:] + list(df)[:-3]]\n",
    "            st.write(\"GPS IDs assignment... OK\")\n",
    "\n",
    "            #if st.session_state['master_get'] == None:\n",
    "            st.session_state['df_copy'] = df\n",
    "            if len(log_new) > 0:\n",
    "                allnew = pd.concat(log_new, axis = 0).reset_index(drop=True)\n",
    "                st.write(\"Thanks for uploading a new version of the sample manifest\")\n",
    "                st.write(f'We have detected a total of {allnew.shape[0]} new samples')\n",
    "                st.write(\"We have assigned new GP2IDs to those. Showing them below...\")\n",
    "                st.dataframe(\n",
    "                allnew.style.set_properties(**{\"background-color\": \"brown\", \"color\": \"lawngreen\"})\n",
    "                #allnew.style.set_properties(**{\"background-color\": \"brown\", \"color\": \"lawngreen\"})\n",
    "                )\n",
    "            else:\n",
    "                aggridPlotter(df)\n",
    "\n",
    "            st.session_state['df_finalids'] = df\n",
    "            st.session_state['master_get'] = 'DONE'\n",
    "\n",
    "        else:\n",
    "            df = st.session_state['df_finalids']\n",
    "            aggridPlotter(df)\n",
    "            # df_builder = GridOptionsBuilder.from_dataframe(st.session_state['df_copy'])\n",
    "            # df_builder.configure_grid_options(alwaysShowHorizontalScroll = True,\n",
    "            #                                     enableRangeSelection=True,\n",
    "            #                                     pagination=True,\n",
    "            #                                     paginationPageSize=10000,\n",
    "            #                                     domLayout='normal')\n",
    "            # godf = df_builder.build()\n",
    "            # AgGrid(st.session_state['df_copy'],gridOptions=godf, theme='streamlit', height=300)\n",
    "            #df = st.session_state['df_finalids']\n",
    "        #st.session_state['master_get'] = 'DONE'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scverse10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
