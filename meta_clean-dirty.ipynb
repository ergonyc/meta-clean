{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASAP CRN Metadata validation - wave 1\n",
    "\n",
    "# ASAP CRN Metadata validation - wave 1\n",
    "\n",
    "15 September 2023\n",
    "Andy Henrie\n",
    "\n",
    "\n",
    "\n",
    "## STEPS\n",
    "\n",
    "### imports\n",
    "- pandas\n",
    "- pathlib\n",
    "\n",
    "### Load CDE for validation\n",
    "- check all columns\n",
    "\n",
    "### Team Lee\n",
    "- load .tsv, csv tables\n",
    "- fix format\n",
    "- load additional metadata\n",
    "\n",
    "- add batch columns\n",
    "- add missing columns\n",
    "\n",
    "\n",
    "### Team Hafler\n",
    "- load excel file with tables\n",
    "- add batch info\n",
    "- add missing columns\n",
    "\n",
    "\n",
    "\n",
    "### Team Hardy\n",
    "- load excel file with tables\n",
    "- add batch info\n",
    "- add missing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Required</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>ClinPath field</th>\n",
       "      <th>team_Hafler type</th>\n",
       "      <th>ClinPath description</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_name</td>\n",
       "      <td>Project Name:   A Title of the overall project...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Dataset Name:   A unique name is required for ...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_description</td>\n",
       "      <td>Project Description:   Brief description of th...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP Team Name:   Name of the ASAP CRN Team. i...</td>\n",
       "      <td>Enum</td>\n",
       "      <td>Required</td>\n",
       "      <td>[\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Lab Name. :   Lab name that is submitting data...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Table                Field   \n",
       "0  STUDY         project_name  \\\n",
       "1  STUDY      project_dataset   \n",
       "2  STUDY  project_description   \n",
       "3  STUDY       ASAP_team_name   \n",
       "4  STUDY        ASAP_lab_name   \n",
       "\n",
       "                                         Description DataType  Required   \n",
       "0  Project Name:   A Title of the overall project...   String  Required  \\\n",
       "1  Dataset Name:   A unique name is required for ...   String  Required   \n",
       "2  Project Description:   Brief description of th...   String  Required   \n",
       "3  ASAP Team Name:   Name of the ASAP CRN Team. i...     Enum  Required   \n",
       "4  Lab Name. :   Lab name that is submitting data...   String  Required   \n",
       "\n",
       "                                Validation  Unnamed: 6 ClinPath field   \n",
       "0                                      NaN         NaN            NaN  \\\n",
       "1                                      NaN         NaN            NaN   \n",
       "2                                      NaN         NaN            NaN   \n",
       "3  [\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\"]         NaN            NaN   \n",
       "4                                      NaN         NaN            NaN   \n",
       "\n",
       "  team_Hafler type ClinPath description Unnamed: 10  \n",
       "0              NaN                  NaN        bard  \n",
       "1              NaN                  NaN         NaN  \n",
       "2              NaN                  NaN         NaN  \n",
       "3              NaN                  NaN         NaN  \n",
       "4              NaN                  NaN         NaN  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDE_path = Path.cwd() / \"CDE.csv\" \n",
    "\n",
    "CDE = pd.read_csv(CDE_path )\n",
    "\n",
    "CDE.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix trailing ...\n",
    "# CDE.loc[CDE['Field']=='ASAP_team_name', 'Validation'] = '[\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\"]'\n",
    "# CDE.loc[CDE['Field']=='ASAP_team_name', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix ['Yes\",\"No\"]\n",
    "# CDE.loc[CDE['Field']=='path_infarcs', 'Validation']='[\"Yes\", \"No\"]'\n",
    "# CDE.loc[CDE['Field']=='path_infarcs', 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_table(table: pd.DataFrame, table_name: str, CDE: pd.DataFrame):\n",
    "    # Filter out rows specific to the given table_name from the CDE\n",
    "    specific_cde_df = CDE[CDE['Table'] == table_name]\n",
    "    \n",
    "    # Extract fields that have a data type of \"Enum\" and retrieve their validation entries\n",
    "    enum_fields_dict = dict(zip(specific_cde_df[specific_cde_df['DataType'] == \"Enum\"]['Field'], \n",
    "                               specific_cde_df[specific_cde_df['DataType'] == \"Enum\"]['Validation']))\n",
    "    \n",
    "    # Extract fields that are marked as \"Required\"\n",
    "    required_fields = specific_cde_df[specific_cde_df['Required'] == \"Required\"]['Field'].tolist()\n",
    "    \n",
    "    # Check for missing \"Required\" fields\n",
    "    missing_required_fields = [field for field in required_fields if field not in table.columns]\n",
    "    \n",
    "    if missing_required_fields:\n",
    "        print(f\"Missing Required Fields in {table_name}: {', '.join(missing_required_fields)}\")\n",
    "    else:\n",
    "        print(f\"All required fields are present in {table_name}.\")\n",
    "\n",
    "    # Check for empty or NaN values in \"Required\" fields\n",
    "    empty_or_nan_fields = {}\n",
    "    for field in required_fields:\n",
    "        if field in table.columns:\n",
    "            invalid_count = table[field].isna().sum()\n",
    "            if invalid_count > 0:\n",
    "                empty_or_nan_fields[field] = invalid_count\n",
    "                \n",
    "    if empty_or_nan_fields:\n",
    "        print(\"\\nFields with Empty or NaN values:\")\n",
    "        for field, count in empty_or_nan_fields.items():\n",
    "            print(f\"{field}: {count} rows\")\n",
    "    else:\n",
    "        print(\"\\nNo empty or NaN values found in required fields.\")\n",
    "    \n",
    "    # Check for invalid Enum field values\n",
    "    invalid_field_values = {}\n",
    "    for field, validation_str in enum_fields_dict.items():\n",
    "        valid_values = eval(validation_str)\n",
    "        if field in table.columns:\n",
    "            invalid_values = table[~table[field].isin(valid_values)][field].unique()\n",
    "            if invalid_values.any():\n",
    "                invalid_field_values[field] = invalid_values\n",
    "    \n",
    "    if invalid_field_values:\n",
    "        print(\"\\nInvalid Field/Value pairs:\")\n",
    "        for field, values in invalid_field_values.items():\n",
    "            print(f\"{field}: {', '.join(map(str, values))}\")\n",
    "    else:\n",
    "        print(f\"\\nAll Enum fields have valid values in {table_name}.\")\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert \n",
    "data_path = Path.home() / (\"Projects/ASAP/team-lee\")\n",
    "metadata_path = data_path / \"metadata/ogmetadata\"\n",
    "\n",
    "SUBJECT = pd.read_csv(f\"{metadata_path}/SUBJECT.tsv\", delimiter=\"\\t\")\n",
    "SAMPLE = pd.read_csv(f\"{metadata_path}/SAMPLE.tsv\",delimiter=\"\\t\")\n",
    "\n",
    "CLINPATH = pd.read_csv(f\"{metadata_path}/CLINPATH.csv\",delimiter=\",\")\n",
    "STUDY = pd.read_csv(f\"{metadata_path}/STUDY.tsv\",delimiter=\"\\t\")\n",
    "PROTOCOL = pd.read_csv(f\"{metadata_path}/PROTOCOL.tsv\",delimiter=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Team-Lee-Bras-Lab-Info</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Note</th>\n",
       "      <th>Required/Optional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is senescence a component of human PD and does...</td>\n",
       "      <td>project_name</td>\n",
       "      <td>Project Name/Title</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unique and clear title.</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human snRNA-seq PD Senesence Jose Bras Team Lee</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Dataset name</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Dataset name is required for each submission...</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Characterize the neuropathological progression...</td>\n",
       "      <td>project_description</td>\n",
       "      <td>Brief description of the goals and objectives ...</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEAM-LEE</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP Team e.g. \"Scherzer\"</td>\n",
       "      <td>Enum</td>\n",
       "      <td>[\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\",....]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bras</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>ASAP Lab under the above team e.g. \"Dong\"</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0           Unnamed: 1   \n",
       "0  Is senescence a component of human PD and does...         project_name  \\\n",
       "1    Human snRNA-seq PD Senesence Jose Bras Team Lee      project_dataset   \n",
       "2  Characterize the neuropathological progression...  project_description   \n",
       "3                                           TEAM-LEE       ASAP_team_name   \n",
       "4                                               Bras        ASAP_lab_name   \n",
       "\n",
       "                                          Unnamed: 2 Team-Lee-Bras-Lab-Info   \n",
       "0                                 Project Name/Title                 String  \\\n",
       "1                                       Dataset name                 String   \n",
       "2  Brief description of the goals and objectives ...                 String   \n",
       "3                          ASAP Team e.g. \"Scherzer\"                   Enum   \n",
       "4          ASAP Lab under the above team e.g. \"Dong\"                 String   \n",
       "\n",
       "                                          Field   \n",
       "0                                           NaN  \\\n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3  [\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\",....]   \n",
       "4                                           NaN   \n",
       "\n",
       "                                         Description Data type  Validation   \n",
       "0                            Unique and clear title.  Required         NaN  \\\n",
       "1  A Dataset name is required for each submission...  Required         NaN   \n",
       "2                                                NaN  Required         NaN   \n",
       "3                                                NaN  Required         NaN   \n",
       "4                                                NaN  Required         NaN   \n",
       "\n",
       "   Note  Required/Optional  \n",
       "0   NaN                NaN  \n",
       "1   NaN                NaN  \n",
       "2   NaN                NaN  \n",
       "3   NaN                NaN  \n",
       "4   NaN                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STUDY = pd.read_csv(metadata_path / \"STUDY.tsv\",delimiter=\"\\t\")\n",
    "STUDY.to_csv(data_path / \"STUDY_.csv\")\n",
    "STUDY = pd.read_csv(data_path / \"STUDY_.csv\")\n",
    "STUDY.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_dataset</th>\n",
       "      <th>project_description</th>\n",
       "      <th>ASAP_team_name</th>\n",
       "      <th>ASAP_lab_name</th>\n",
       "      <th>PI_full_name</th>\n",
       "      <th>PI_email</th>\n",
       "      <th>submitter_id</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submittor_email</th>\n",
       "      <th>...</th>\n",
       "      <th>other_funding_source</th>\n",
       "      <th>publication_DOI</th>\n",
       "      <th>publication_PMID</th>\n",
       "      <th>number_of_brain_samples</th>\n",
       "      <th>brain_regions</th>\n",
       "      <th>types_of_samples</th>\n",
       "      <th>PI_ORCHID</th>\n",
       "      <th>PI_google_scholar_id</th>\n",
       "      <th>DUA_version</th>\n",
       "      <th>metadata_version_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>project_description</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>PI_full_name</td>\n",
       "      <td>PI_email</td>\n",
       "      <td>submitter_id</td>\n",
       "      <td>submitter_name</td>\n",
       "      <td>submittor_email</td>\n",
       "      <td>...</td>\n",
       "      <td>other_funding_source</td>\n",
       "      <td>publication_DOI</td>\n",
       "      <td>publication_PMID</td>\n",
       "      <td>number_of_brain_samples</td>\n",
       "      <td>brain_regions</td>\n",
       "      <td>types_of_samples</td>\n",
       "      <td>PI_ORCHID</td>\n",
       "      <td>PI_google_scholar_id</td>\n",
       "      <td>DUA_version</td>\n",
       "      <td>metadata_version_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is senescence a component of human PD and does...</td>\n",
       "      <td>Human snRNA-seq PD Senesence Jose Bras Team Lee</td>\n",
       "      <td>Characterize the neuropathological progression...</td>\n",
       "      <td>TEAM-LEE</td>\n",
       "      <td>Bras</td>\n",
       "      <td>Jose, Bras</td>\n",
       "      <td>jose.bras@vai.org</td>\n",
       "      <td>Lee, L, Marshall ; Kimberly, E, Paquette ; Kai...</td>\n",
       "      <td>Kaitlyn E Westra</td>\n",
       "      <td>kaitlyn.westra@vai.org</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>hippocampus; middle frontal gyrus; substantia ...</td>\n",
       "      <td>human PD and control postmortem brains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                       project_name   \n",
       "0                                       project_name  \\\n",
       "1  Is senescence a component of human PD and does...   \n",
       "\n",
       "0                                  project_dataset   \n",
       "0                                  project_dataset  \\\n",
       "1  Human snRNA-seq PD Senesence Jose Bras Team Lee   \n",
       "\n",
       "0                                project_description  ASAP_team_name   \n",
       "0                                project_description  ASAP_team_name  \\\n",
       "1  Characterize the neuropathological progression...        TEAM-LEE   \n",
       "\n",
       "0  ASAP_lab_name  PI_full_name           PI_email   \n",
       "0  ASAP_lab_name  PI_full_name           PI_email  \\\n",
       "1           Bras    Jose, Bras  jose.bras@vai.org   \n",
       "\n",
       "0                                       submitter_id    submitter_name   \n",
       "0                                       submitter_id    submitter_name  \\\n",
       "1  Lee, L, Marshall ; Kimberly, E, Paquette ; Kai...  Kaitlyn E Westra   \n",
       "\n",
       "0         submittor_email  ...  other_funding_source  publication_DOI   \n",
       "0         submittor_email  ...  other_funding_source  publication_DOI  \\\n",
       "1  kaitlyn.westra@vai.org  ...                   NaN              NaN   \n",
       "\n",
       "0  publication_PMID  number_of_brain_samples   \n",
       "0  publication_PMID  number_of_brain_samples  \\\n",
       "1               NaN                       75   \n",
       "\n",
       "0                                      brain_regions   \n",
       "0                                      brain_regions  \\\n",
       "1  hippocampus; middle frontal gyrus; substantia ...   \n",
       "\n",
       "0                        types_of_samples  PI_ORCHID  PI_google_scholar_id   \n",
       "0                        types_of_samples  PI_ORCHID  PI_google_scholar_id  \\\n",
       "1  human PD and control postmortem brains        NaN                   NaN   \n",
       "\n",
       "0  DUA_version  metadata_version_date  \n",
       "0  DUA_version  metadata_version_date  \n",
       "1       unsure                    NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fix STUDY formatting\n",
    "tmp = pd.DataFrame()\n",
    "tmp = STUDY[[\"Unnamed: 1\",\"Unnamed: 0\"]].transpose().reset_index().drop(columns=[\"index\"])\n",
    "tmp.columns = tmp.iloc[0]\n",
    "STUDY = tmp.drop([0])\n",
    "# STUDY[[\"Unnamed: 1\"]].transpose().reset_index().drop(columns=[\"index\"]), tmp\n",
    "\n",
    "tmp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect additional metadata from covar.csv .. i.e. batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata_path = Path.home() / (\"Projects/ASAP/team-lee/metadata\")\n",
    "HIP_covar = pd.read_csv(f\"{metadata_path}/HIP/covar.csv\")\n",
    "HIP_cases = pd.read_csv(f\"{metadata_path}/HIP/PD_ASAP_Sample_batch_information_banner_cases.csv\").dropna(axis=0,how='all')\n",
    "HIP_control = pd.read_csv(f\"{metadata_path}/HIP/PD_ASAP_Sample_batch_information_banner_controls.csv\")\n",
    "\n",
    "MFG_covar = pd.read_csv(f\"{metadata_path}/MFG/covar.csv\") # includes 'PMI' ?\n",
    "MFG_cases = pd.read_csv(f\"{metadata_path}/MFG/PD_ASAP_Sample_batch_information_banner_cases.csv\").dropna(axis=0,how='all')\n",
    "MFG_control = pd.read_csv(f\"{metadata_path}/MFG/PD_ASAP_Sample_batch_information_banner_controls.csv\")\n",
    "\n",
    "\n",
    "SN_covar = pd.read_csv(f\"{metadata_path}/SN/covar.csv\")\n",
    "SN_cases = pd.read_csv(f\"{metadata_path}/SN/PD_ASAP_Sample_batch_information_banner_cases.csv\").dropna(axis=0,how='all')\n",
    "SN_control = pd.read_csv(f\"{metadata_path}/SN/PD_ASAP_Sample_batch_information_banner_controls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hippocampus samples\n",
    "# HIP_cases[\"GROUPcv\"]=\"PD\"\n",
    "# HIP_control[\"GROUPcv\"]=\"HC\"\n",
    "\n",
    "HIP_meta = pd.concat([HIP_cases, HIP_control], axis=0, ignore_index=True)\n",
    "HIP_meta[\"GROUPcv\"]= HIP_meta[\"PD\"].apply(lambda x: \"PD\" if (x==\"yes\") else \"HC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "HIP_meta['MERGE_ID'] = \"HIP_\" + HIP_meta['GROUPcv'] +\"_\" + HIP_meta['CaseID'].str.replace('-','')\n",
    "HIP_covar['MERGE_ID'] = HIP_covar['COUNT_ID']\n",
    "# the fastqs follow COUNT_ID insteald of SEQ_ID naming convention\n",
    "HIP_covar['SEQ_ID'] = HIP_covar['COUNT_ID']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a bug in the meta table... skip for now\n",
    "HIP_TABLE = pd.merge(HIP_covar, HIP_meta, on='MERGE_ID', how='outer')\n",
    "\n",
    "# HIP_TABLE = HIP_covar\n",
    "HIP_TABLE['subdir']=\"HIP\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = HIP_TABLE[[\"MERGE_ID\",\"SEQ_ID\",\"GROUPcv\",\"subdir\",'PD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### medial frontal gyrus samples\n",
    "MFG_meta = pd.concat([MFG_cases, MFG_control], axis=0, ignore_index=True)\n",
    "MFG_meta[\"GROUPcv\"]= MFG_meta[\"PD\"].apply(lambda x: \"PD\" if (x==\"yes\") else \"HC\")\n",
    "\n",
    "# make a MERGE_ID column because the formatting is inconsistent\n",
    "MFG_meta['MERGE_ID'] = \"MFG_\" + MFG_meta['GROUPcv'] +\"_\" + MFG_meta['CaseID'].str.replace('-','')\n",
    "MFG_covar['MERGE_ID'] = MFG_covar['SAMPLE']\n",
    "# the fastqs are in SEQ_ID \n",
    "\n",
    "# there's a bug in the meta table... skip for now\n",
    "MFG_TABLE = pd.merge(MFG_covar, MFG_meta, on='MERGE_ID', how='inner')\n",
    "MFG_TABLE['subdir']=\"MFG\"\n",
    "\n",
    "\n",
    "\n",
    "# Substantia Nigra\n",
    "SN_meta = pd.concat([SN_cases, SN_control], axis=0, ignore_index=True)\n",
    "SN_meta[\"GROUPcv\"] = SN_meta[\"PD\"].apply(lambda x: \"PD\" if (x==\"yes\") else \"HC\")\n",
    "\n",
    "SN_meta['MERGE_ID'] = \"SN_\" + MFG_meta['GROUPcv'] +\"_\" + MFG_meta['CaseID'].str.replace('-','')\n",
    "SN_covar['MERGE_ID'] = SN_covar['SAMPLE']\n",
    "\n",
    "# there's a bug in the meta table... skip for now\n",
    "SN_TABLE = pd.merge(SN_covar, SN_meta, on='MERGE_ID', how='outer')\n",
    "SN_TABLE['subdir']=\"SN\"\n",
    "\n",
    "\n",
    "### concatenate SN, MSG, and HIP tables into one 'all_samples' table\n",
    "all_samples = pd.concat([HIP_TABLE, MFG_TABLE, SN_TABLE], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_ALL = SAMPLE.merge(all_samples, left_on='sample_id', right_on='MERGE_ID', how='left')\n",
    "SAMPLE_ALL.to_csv(\"alternate_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_og = SAMPLE.copy()\n",
    "SAMPLE['batch'] = SAMPLE_ALL['BATCH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the fields with DataType as \"Enum\" or \"String\" for the \"sample\" table from CDE.csv\n",
    "\n",
    "# Define a function to only capitalize the first letter of a string\n",
    "def capitalize_first_letter(s):\n",
    "    if not isinstance(s, str) or len(s) == 0:  # Check if the value is a string and non-empty\n",
    "        return s\n",
    "    return s[0].upper() + s[1:]\n",
    "\n",
    "def force_enum_string(df, df_name, CDE):\n",
    "\n",
    "    string_enum_fields = CDE[(CDE[\"Table\"] == df_name) & \n",
    "                                (CDE[\"DataType\"].isin([\"Enum\", \"String\"]))][\"Field\"].tolist()\n",
    "    # Convert the specified columns to string data type using astype() without a loop\n",
    "    columns_to_convert = {col: 'str' for col in string_enum_fields if col in df.columns}\n",
    "    df = df.astype(columns_to_convert)\n",
    "\n",
    "    # enum_fields = CDE[ (CDE[\"Table\"] == df_name) & \n",
    "    #                             (CDE[\"DataType\"]==\"Enum\") ][\"Field\"].tolist()\n",
    "    \n",
    "    for col in string_enum_fields:\n",
    "        if col in df.columns and col != \"assay\":\n",
    "            df[col] = df[col].apply(capitalize_first_letter)\n",
    "\n",
    "    return df\n",
    "\n",
    "SAMPLE = force_enum_string(SAMPLE, \"SAMPLE\", CDE)\n",
    "# for field in string_enum_fields:\n",
    "#     if field in SAMPLE.columns:\n",
    "#         SAMPLE[field] = SAMPLE[field].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_dataset</th>\n",
       "      <th>project_description</th>\n",
       "      <th>ASAP_team_name</th>\n",
       "      <th>ASAP_lab_name</th>\n",
       "      <th>PI_full_name</th>\n",
       "      <th>PI_email</th>\n",
       "      <th>submitter_id</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submittor_email</th>\n",
       "      <th>...</th>\n",
       "      <th>other_funding_source</th>\n",
       "      <th>publication_DOI</th>\n",
       "      <th>publication_PMID</th>\n",
       "      <th>number_of_brain_samples</th>\n",
       "      <th>brain_regions</th>\n",
       "      <th>types_of_samples</th>\n",
       "      <th>PI_ORCHID</th>\n",
       "      <th>PI_google_scholar_id</th>\n",
       "      <th>DUA_version</th>\n",
       "      <th>metadata_version_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is senescence a component of human PD and does...</td>\n",
       "      <td>Human snRNA-seq PD Senesence Jose Bras Team Lee</td>\n",
       "      <td>Characterize the neuropathological progression...</td>\n",
       "      <td>TEAM-LEE</td>\n",
       "      <td>Bras</td>\n",
       "      <td>Jose, Bras</td>\n",
       "      <td>jose.bras@vai.org</td>\n",
       "      <td>Lee, L, Marshall ; Kimberly, E, Paquette ; Kai...</td>\n",
       "      <td>Kaitlyn E Westra</td>\n",
       "      <td>kaitlyn.westra@vai.org</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>hippocampus; middle frontal gyrus; substantia ...</td>\n",
       "      <td>human PD and control postmortem brains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unsure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                       project_name   \n",
       "1  Is senescence a component of human PD and does...  \\\n",
       "\n",
       "0                                  project_dataset   \n",
       "1  Human snRNA-seq PD Senesence Jose Bras Team Lee  \\\n",
       "\n",
       "0                                project_description ASAP_team_name   \n",
       "1  Characterize the neuropathological progression...       TEAM-LEE  \\\n",
       "\n",
       "0 ASAP_lab_name PI_full_name           PI_email   \n",
       "1          Bras   Jose, Bras  jose.bras@vai.org  \\\n",
       "\n",
       "0                                       submitter_id    submitter_name   \n",
       "1  Lee, L, Marshall ; Kimberly, E, Paquette ; Kai...  Kaitlyn E Westra  \\\n",
       "\n",
       "0         submittor_email  ... other_funding_source publication_DOI   \n",
       "1  kaitlyn.westra@vai.org  ...                  NaN             NaN  \\\n",
       "\n",
       "0 publication_PMID number_of_brain_samples   \n",
       "1              NaN                      75  \\\n",
       "\n",
       "0                                      brain_regions   \n",
       "1  hippocampus; middle frontal gyrus; substantia ...  \\\n",
       "\n",
       "0                        types_of_samples PI_ORCHID PI_google_scholar_id   \n",
       "1  human PD and control postmortem brains       NaN                  NaN  \\\n",
       "\n",
       "0 DUA_version metadata_version_date  \n",
       "1      unsure                   NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in STUDY: contributor_names\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "other_funding_source: 1 rows\n",
      "publication_DOI: 1 rows\n",
      "publication_PMID: 1 rows\n",
      "\n",
      "All Enum fields have valid values in STUDY.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with STUDY.csv and CDE.csv\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in STUDY.\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "other_funding_source: 1 rows\n",
      "publication_DOI: 1 rows\n",
      "publication_PMID: 1 rows\n",
      "\n",
      "All Enum fields have valid values in STUDY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Need to rename submitter_id to contributor_names\n",
    "STUDY = STUDY.rename(columns={\"submitter_id\": \"contributor_names\"})\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in PROTOCOL.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "All Enum fields have valid values in PROTOCOL.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with PROTOCOL.csv and CDE.csv\n",
    "validate_table(PROTOCOL, \"PROTOCOL\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in SUBJECT.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "All Enum fields have valid values in SUBJECT.\n"
     ]
    }
   ],
   "source": [
    "# Extract the fields with DataType as \"Enum\" or \"String\" for the \"sample\" table from CDE.csv\n",
    "\n",
    "\n",
    "SUBJECT = force_enum_string(SUBJECT, \"SUBJECT\", CDE)\n",
    "\n",
    "# Testing the function with SUBJECT.csv and CDE.csv\n",
    "validate_table(SUBJECT, \"SUBJECT\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in SAMPLE: file_MD5\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "source_RIN: 75 rows\n",
      "RIN: 75 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "file_type: Fastq\n"
     ]
    }
   ],
   "source": [
    "SAMPLE = force_enum_string(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "\n",
    "# Testing the function with SAMPLE.csv and CDE.csv\n",
    "validate_table(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "# sequence length will need to be converted to a string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE['file_type'] = SAMPLE['file_type'].replace({\"Fastq\":\"fastq\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>source_sample_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>replicate</th>\n",
       "      <th>replicate_count</th>\n",
       "      <th>repeated_sample</th>\n",
       "      <th>tissue</th>\n",
       "      <th>brain_region</th>\n",
       "      <th>source_RIN</th>\n",
       "      <th>RIN</th>\n",
       "      <th>...</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>DV2000</th>\n",
       "      <th>pm_PH</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFG_HC_1225</td>\n",
       "      <td>12-25</td>\n",
       "      <td>12-25</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Middle_Frontal_Gyrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>UBERON:0002702</td>\n",
       "      <td>NA(multiple)</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>BATCH_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFG_HC_0602</td>\n",
       "      <td>06-02</td>\n",
       "      <td>06-02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Middle_Frontal_Gyrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>UBERON:0002702</td>\n",
       "      <td>NA(multiple)</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>BATCH_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MFG_PD_0009</td>\n",
       "      <td>00-09</td>\n",
       "      <td>00-09</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Middle_Frontal_Gyrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0002702</td>\n",
       "      <td>NA(multiple)</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>BATCH_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MFG_PD_1921</td>\n",
       "      <td>19-21</td>\n",
       "      <td>19-21</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Middle_Frontal_Gyrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0002702</td>\n",
       "      <td>NA(multiple)</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>BATCH_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MFG_PD_2058</td>\n",
       "      <td>20-58</td>\n",
       "      <td>20-58</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Middle_Frontal_Gyrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MONDO:0005180</td>\n",
       "      <td>UBERON:0002702</td>\n",
       "      <td>NA(multiple)</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>BATCH_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id source_sample_id subject_id replicate  replicate_count   \n",
       "0  MFG_HC_1225            12-25      12-25      Rep1                1  \\\n",
       "1  MFG_HC_0602            06-02      06-02      Rep1                1   \n",
       "2  MFG_PD_0009            00-09      00-09      Rep1                1   \n",
       "3  MFG_PD_1921            19-21      19-21      Rep1                1   \n",
       "4  MFG_PD_2058            20-58      20-58      Rep1                1   \n",
       "\n",
       "   repeated_sample tissue          brain_region  source_RIN  RIN  ...   \n",
       "0                0  Brain  Middle_Frontal_Gyrus         NaN  NaN  ...  \\\n",
       "1                0  Brain  Middle_Frontal_Gyrus         NaN  NaN  ...   \n",
       "2                0  Brain  Middle_Frontal_Gyrus         NaN  NaN  ...   \n",
       "3                0  Brain  Middle_Frontal_Gyrus         NaN  NaN  ...   \n",
       "4                0  Brain  Middle_Frontal_Gyrus         NaN  NaN  ...   \n",
       "\n",
       "  self_reported_ethnicity_ontology_term_id  disease_ontology_term_id   \n",
       "0                                  Unknown              PATO:0000461  \\\n",
       "1                                  Unknown              PATO:0000461   \n",
       "2                                  Unknown             MONDO:0005180   \n",
       "3                                  Unknown             MONDO:0005180   \n",
       "4                                  Unknown             MONDO:0005180   \n",
       "\n",
       "  tissue_ontology_term_id cell_type_ontology_term_id assay_ontology_term_id   \n",
       "0          UBERON:0002702               NA(multiple)            EFO:0030004  \\\n",
       "1          UBERON:0002702               NA(multiple)            EFO:0030004   \n",
       "2          UBERON:0002702               NA(multiple)            EFO:0030004   \n",
       "3          UBERON:0002702               NA(multiple)            EFO:0030004   \n",
       "4          UBERON:0002702               NA(multiple)            EFO:0030004   \n",
       "\n",
       "  suspension_type DV2000 pm_PH donor_id    batch  \n",
       "0         nucleus    NaN   NaN      Nan  BATCH_4  \n",
       "1         nucleus    NaN   NaN      Nan  BATCH_4  \n",
       "2         nucleus    NaN   NaN      Nan  BATCH_4  \n",
       "3         nucleus    NaN   NaN      Nan  BATCH_4  \n",
       "4         nucleus    NaN   NaN      Nan  BATCH_4  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the colunn order of SAMPLE match the CDE.Field\n",
    "# SAMPLE = SAMPLE[CDE.Field.tolist()]\n",
    "SAMPLE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix file_name and file_MD5 which need to be exploded (do this last for simplicity. i.e. to keep one sample per row rather than one file per row)\n",
    "\n",
    "# Step 1: Split the values in the columns based on commas\n",
    "SAMPLE['file_name'] = SAMPLE['file_name'].str.split(',')\n",
    "SAMPLE['file_MD5(R1,R2)'] = SAMPLE['file_MD5(R1,R2)'].str.split(',')\n",
    "\n",
    "# Step 2: Explode both 'file_name' and 'file_MD5(R1,R2)' columns together\n",
    "SAMPLE = SAMPLE.explode(['file_name', 'file_MD5(R1,R2)'])\n",
    "\n",
    "# Step 3: Rename the \"file_MD5(R1,R2)\" column to \"file_MD5\"\n",
    "SAMPLE = SAMPLE.rename(columns={\"file_MD5(R1,R2)\": \"file_MD5\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in CLINPATH.\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "age_at_onset: 75 rows\n",
      "age_at_diagnosis: 75 rows\n",
      "first_motor_symptom: 75 rows\n",
      "path_year_death: 75 rows\n",
      "brain_weight: 75 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "region_level_2: Hippocampus\n",
      "hx_melanoma: Nan\n",
      "education_level: Nan\n",
      "APOE_e4_status: 23\n",
      "cognitive_status: Nan\n",
      "path_braak_asyn: L. Olfactory Bulb-Only, Lla. Brainstem Predominant, Llb. Limbic Predominant, LV. Neocortical, Lll. Brainstem/Limbic, 0. No Lewy bodies\n",
      "path_cerad: Nan\n",
      "path_thal: Nan\n",
      "path_mckeith: L. Olfactory Bulb-Only, Lla. Brainstem Predominant, Llb. Limbic Predominant, LV. Neocortical, Lll. Brainstem/Limbic, 0. No Lewy bodies\n",
      "sn_neuronal_loss: Nan\n",
      "path_infarcs: Nan\n",
      "path_nia_ri: Criteria not met, Not AD\n",
      "path_nia_aa_a: Nan\n",
      "path_nia_aa_b: Nan\n",
      "path_nia_aa_c: Nan\n",
      "TDP43: Nan, Na\n",
      "arteriolosclerosis_severity_scale: Nan\n",
      "amyloid_angiopathy_severity_scale: Nan, Cerebral amyloid angiopathy, temporal and occipital lobe, Cerebral amyloid angiopathy, frontal lobe\n",
      "path_ad_level: Microscopic changes of Alzheimer's disease, insufficient for diagnosis, Microscopic lesions of Alzheimer's disease, insufficient for diagnosis\n"
     ]
    }
   ],
   "source": [
    "CLINPATH = force_enum_string(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "# Testing the function with CLINPATH.csv and CDE.csv\n",
    "validate_table(CLINPATH, \"CLINPATH\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLINPATH['region_level_2'].unique()\n",
    "\n",
    "# change \"Hippocampus\" to \"CA1-CA4\"\n",
    "CLINPATH['region_level_2'] = CLINPATH['region_level_2'].replace('Hippocampus', 'CA1-CA4')\n",
    "\n",
    "# skip hx_melanoma and education level for now as there is not a \"Unknown\" or \"Not Reported\" option in the CDE\n",
    "\n",
    "# leave te APOE_e4_status as is for now . multiple are coded as \"2,3\" \n",
    "# leave cognitive status as is, since there is no \"Unknown\" or \"Not Reported\" option in the CDE\n",
    "\n",
    "# potential \"path_braak_asyn\" coding \n",
    "braak_map = {'L. Olfactory Bulb-Only':\"1/2\", 'Lla. Brainstem Predominant':\"3\",\n",
    "       'Llb. Limbic Predominant':\"3/4\", 'LV. Neocortical':\"5\",\n",
    "       'Lll. Brainstem/Limbic':\"3/4\", '0. No Lewy bodies':\"0\"}\n",
    "# set to NaN for now since this is actualy path_mckeith coding\n",
    "\n",
    "CLINPATH['path_braak_asyn'] = \"NaN\"\n",
    "\n",
    "mckeith_map = {'L. Olfactory Bulb-Only':\"Olfactory bulb only\", 'Lla. Brainstem Predominant':\"Brainstem\",\n",
    "       'Llb. Limbic Predominant':\"Limbic (transitional)\", 'LV. Neocortical':\"Neocortical\",\n",
    "       'Lll. Brainstem/Limbic':\"Amygdala Predominant\", '0. No Lewy bodies':\"Absent\"}\n",
    "\n",
    "\n",
    "CLINPATH['path_mckeith'] = CLINPATH['path_mckeith'].replace(mckeith_map)\n",
    "\n",
    "# leave path_nia_ri like this for now. not sure how to map \"criteria not met\" and \"Not AD\"\n",
    "\n",
    "# leave path_nia_ri like this for now. not sure how to map 'Cerebral amyloid angiopathy, temporal and occipital lobe','Cerebral amyloid angiopathy, frontal lobe']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_ALL_CP = SAMPLE_ALL.merge(CLINPATH, on='sample_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ALL_CP.to_csv(\"./clean/team-Lee/auxilarry_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write clean metadata tables according to CDE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE = SAMPLE[CDE[CDE[\"Table\"]==\"SAMPLE\"].Field.tolist()]\n",
    "\n",
    "\n",
    "def reorder_table_to_CDE(df, df_name, CDE):\n",
    "    col_order = CDE[CDE[\"Table\"]==df_name].Field.tolist()\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    for col in col_order:\n",
    "        if col in df.columns:   \n",
    "            df_out[col] = df[col]\n",
    "        else:\n",
    "            df_out[col] = \"NaN\"\n",
    "\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the column order\n",
    "STUDY = reorder_table_to_CDE(STUDY, \"STUDY\", CDE)\n",
    "SAMPLE = reorder_table_to_CDE(SAMPLE, \"SAMPLE\", CDE)\n",
    "PROTOCOL = reorder_table_to_CDE(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "SUBJECT = reorder_table_to_CDE(SUBJECT, \"SUBJECT\", CDE)     \n",
    "CLINPATH = reorder_table_to_CDE(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "# write the clean metadata\n",
    "STUDY.to_csv(data_path / \"metadata/STUDY.csv\")\n",
    "PROTOCOL.to_csv(data_path / \"metadata/PROTOCOL.csv\")\n",
    "CLINPATH.to_csv(data_path / \"metadata/CLINPATH.csv\")\n",
    "SAMPLE.to_csv(data_path / \"metadata/SAMPLE.csv\")\n",
    "SUBJECT.to_csv(data_path / \"metadata/SUBJECT.csv\")\n",
    "\n",
    "# also writh them to clean...\n",
    "# \n",
    "#  \n",
    "\n",
    "export_root = Path.cwd() / \"clean/team-Lee\"\n",
    "if not export_root.exists():\n",
    "    export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "STUDY.to_csv( export_root / \"STUDY.csv\")\n",
    "PROTOCOL.to_csv(export_root / \"PROTOCOL.csv\")\n",
    "SAMPLE.to_csv(export_root / \"SAMPLE.csv\")\n",
    "SUBJECT.to_csv(export_root / \"SUBJECT.csv\")\n",
    "CLINPATH.to_csv(export_root / \"CLINPATH.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ergonyc/Projects/ASAP/team-lee')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Hafler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ergonyc/Projects/ASAP/team-hafler/metadata')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert to seurat Object\n",
    "data_path = Path.home() / (\"Projects/ASAP\")\n",
    "metadata_path = data_path / \"team-hafler/metadata\"\n",
    "\n",
    "sheets = [\"SAMPLE\",\"SUBJECT\",\"CLINPATH\",\"STUDY\",\"PROTOCOL\"]\n",
    "excel_path = data_path / \"ASAP_CDE_ALL_Team_Hafler_v1.xlsx\"\n",
    "STUDY = pd.read_excel(excel_path,sheet_name=\"STUDY\",header=1).drop(columns=\"Field\")\n",
    "CLINPATH = pd.read_excel(excel_path,sheet_name=\"CLINPATH\",header=1).drop(columns=\"Field\")\n",
    "SUBJECT = pd.read_excel(excel_path,sheet_name=\"SUBJECT\",header=1).drop(columns=\"Field\")\n",
    "SAMPLE = pd.read_excel(excel_path,sheet_name=\"SAMPLE\",header=1).drop(columns=\"Field\")\n",
    "PROTOCOL = pd.read_excel(excel_path,sheet_name=\"PROTOCOL\",header=1).drop(columns=\"Field\")\n",
    "metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_hafler_batch(sample_df):\n",
    "\n",
    "    # First batch: HSDG07HC HSDG10HC HSDG148PD HSDG199PD\n",
    "    # batch[batch.sample_id in ['hSDG07HC', 'hSDG10HC', 'hSDG148PD', 'hSDG199PD']]=1\n",
    "    Batch_1 = ['hSDG07', 'hSDG10', 'hSDG148', 'hSDG199'] \n",
    "    # Second batch: hsDG101HC hsDG13HC hsDG151PD hsDG197PD hsDG30HC hsDG99HC\n",
    "    Batch_2 = ['hSDG101', 'hSDG13', 'hSDG151', 'hSDG197', 'hSDG30', 'hSDG99']\n",
    "    # Third batch: hsDG142PD hsDG208PD\n",
    "    Batch_3 = ['hSDG142', 'hSDG208'] \n",
    "\n",
    "\n",
    "    batch_col = []\n",
    "    for row in sample_df.sample_id:\n",
    "        if row in Batch_1:\n",
    "            batch_col.append(\"Batch_1\")\n",
    "        elif row in Batch_2:\n",
    "            batch_col.append(\"Batch_2\")\n",
    "        elif row in Batch_3:\n",
    "            batch_col.append(\"Batch_3\")\n",
    "        else:\n",
    "            print(\"ERROR >>>>>>>> not no batch info\")\n",
    "            batch_col.append(\"\")\n",
    "\n",
    "\n",
    "    sample_df['batch'] = batch_col\n",
    "    return sample_df\n",
    "\n",
    "SAMPLE = add_hafler_batch(SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>source_sample_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>replicate</th>\n",
       "      <th>replicate_count</th>\n",
       "      <th>repeated_sample</th>\n",
       "      <th>batch</th>\n",
       "      <th>tissue</th>\n",
       "      <th>brain_region</th>\n",
       "      <th>source_RIN</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_ontology_term_id</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>DV2000</th>\n",
       "      <th>pm_PH</th>\n",
       "      <th>donor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hSDG07</td>\n",
       "      <td>hSDG07</td>\n",
       "      <td>HC01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hSDG07</td>\n",
       "      <td>hSDG07</td>\n",
       "      <td>HC01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hSDG07</td>\n",
       "      <td>hSDG07</td>\n",
       "      <td>HC01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hSDG101</td>\n",
       "      <td>hSDG101</td>\n",
       "      <td>HC03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hSDG101</td>\n",
       "      <td>hSDG101</td>\n",
       "      <td>HC03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hSDG101</td>\n",
       "      <td>hSDG101</td>\n",
       "      <td>HC03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hSDG10</td>\n",
       "      <td>hSDG10</td>\n",
       "      <td>HC04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hSDG10</td>\n",
       "      <td>hSDG10</td>\n",
       "      <td>HC04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hSDG10</td>\n",
       "      <td>hSDG10</td>\n",
       "      <td>HC04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hSDG13</td>\n",
       "      <td>hSDG13</td>\n",
       "      <td>HC02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hSDG13</td>\n",
       "      <td>hSDG13</td>\n",
       "      <td>HC02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hSDG13</td>\n",
       "      <td>hSDG13</td>\n",
       "      <td>HC02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hSDG142</td>\n",
       "      <td>hSDG142</td>\n",
       "      <td>PD04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hSDG142</td>\n",
       "      <td>hSDG142</td>\n",
       "      <td>PD04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hSDG142</td>\n",
       "      <td>hSDG142</td>\n",
       "      <td>PD04</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hSDG148</td>\n",
       "      <td>hSDG148</td>\n",
       "      <td>PD05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hSDG148</td>\n",
       "      <td>hSDG148</td>\n",
       "      <td>PD05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hSDG148</td>\n",
       "      <td>hSDG148</td>\n",
       "      <td>PD05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hSDG151</td>\n",
       "      <td>hSDG151</td>\n",
       "      <td>PD01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hSDG151</td>\n",
       "      <td>hSDG151</td>\n",
       "      <td>PD01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hSDG151</td>\n",
       "      <td>hSDG151</td>\n",
       "      <td>PD01</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hSDG197</td>\n",
       "      <td>hSDG197</td>\n",
       "      <td>PD02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hSDG197</td>\n",
       "      <td>hSDG197</td>\n",
       "      <td>PD02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hSDG197</td>\n",
       "      <td>hSDG197</td>\n",
       "      <td>PD02</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hSDG199</td>\n",
       "      <td>hSDG199</td>\n",
       "      <td>PD06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hSDG199</td>\n",
       "      <td>hSDG199</td>\n",
       "      <td>PD06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hSDG199</td>\n",
       "      <td>hSDG199</td>\n",
       "      <td>PD06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hSDG208</td>\n",
       "      <td>hSDG208</td>\n",
       "      <td>PD03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hSDG208</td>\n",
       "      <td>hSDG208</td>\n",
       "      <td>PD03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hSDG208</td>\n",
       "      <td>hSDG208</td>\n",
       "      <td>PD03</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hSDG30</td>\n",
       "      <td>hSDG30</td>\n",
       "      <td>HC05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hSDG30</td>\n",
       "      <td>hSDG30</td>\n",
       "      <td>HC05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hSDG30</td>\n",
       "      <td>hSDG30</td>\n",
       "      <td>HC05</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>hSDG99</td>\n",
       "      <td>hSDG99</td>\n",
       "      <td>HC06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hSDG99</td>\n",
       "      <td>hSDG99</td>\n",
       "      <td>HC06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hSDG99</td>\n",
       "      <td>hSDG99</td>\n",
       "      <td>HC06</td>\n",
       "      <td>Rep1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Prefrontal Cortex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id source_sample_id subject_id replicate  replicate_count   \n",
       "0     hSDG07           hSDG07       HC01      Rep1                1  \\\n",
       "1     hSDG07           hSDG07       HC01      Rep1                1   \n",
       "2     hSDG07           hSDG07       HC01      Rep1                1   \n",
       "3    hSDG101          hSDG101       HC03      Rep1                1   \n",
       "4    hSDG101          hSDG101       HC03      Rep1                1   \n",
       "5    hSDG101          hSDG101       HC03      Rep1                1   \n",
       "6     hSDG10           hSDG10       HC04      Rep1                1   \n",
       "7     hSDG10           hSDG10       HC04      Rep1                1   \n",
       "8     hSDG10           hSDG10       HC04      Rep1                1   \n",
       "9     hSDG13           hSDG13       HC02      Rep1                1   \n",
       "10    hSDG13           hSDG13       HC02      Rep1                1   \n",
       "11    hSDG13           hSDG13       HC02      Rep1                1   \n",
       "12   hSDG142          hSDG142       PD04      Rep1                1   \n",
       "13   hSDG142          hSDG142       PD04      Rep1                1   \n",
       "14   hSDG142          hSDG142       PD04      Rep1                1   \n",
       "15   hSDG148          hSDG148       PD05      Rep1                1   \n",
       "16   hSDG148          hSDG148       PD05      Rep1                1   \n",
       "17   hSDG148          hSDG148       PD05      Rep1                1   \n",
       "18   hSDG151          hSDG151       PD01      Rep1                1   \n",
       "19   hSDG151          hSDG151       PD01      Rep1                1   \n",
       "20   hSDG151          hSDG151       PD01      Rep1                1   \n",
       "21   hSDG197          hSDG197       PD02      Rep1                1   \n",
       "22   hSDG197          hSDG197       PD02      Rep1                1   \n",
       "23   hSDG197          hSDG197       PD02      Rep1                1   \n",
       "24   hSDG199          hSDG199       PD06      Rep1                1   \n",
       "25   hSDG199          hSDG199       PD06      Rep1                1   \n",
       "26   hSDG199          hSDG199       PD06      Rep1                1   \n",
       "27   hSDG208          hSDG208       PD03      Rep1                1   \n",
       "28   hSDG208          hSDG208       PD03      Rep1                1   \n",
       "29   hSDG208          hSDG208       PD03      Rep1                1   \n",
       "30    hSDG30           hSDG30       HC05      Rep1                1   \n",
       "31    hSDG30           hSDG30       HC05      Rep1                1   \n",
       "32    hSDG30           hSDG30       HC05      Rep1                1   \n",
       "33    hSDG99           hSDG99       HC06      Rep1                1   \n",
       "34    hSDG99           hSDG99       HC06      Rep1                1   \n",
       "35    hSDG99           hSDG99       HC06      Rep1                1   \n",
       "\n",
       "    repeated_sample    batch tissue       brain_region  source_RIN  ...   \n",
       "0                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...  \\\n",
       "1                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "2                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "3                 0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "4                 0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "5                 0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "6                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "7                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "8                 0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "9                 0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "10                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "11                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "12                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "13                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "14                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "15                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "16                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "17                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "18                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "19                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "20                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "21                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "22                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "23                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "24                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "25                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "26                0  Batch_1  Brain  Prefrontal Cortex         NaN  ...   \n",
       "27                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "28                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "29                0  Batch_3  Brain  Prefrontal Cortex         NaN  ...   \n",
       "30                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "31                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "32                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "33                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "34                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "35                0  Batch_2  Brain  Prefrontal Cortex         NaN  ...   \n",
       "\n",
       "    sex_ontology_term_id self_reported_ethnicity_ontology_term_id   \n",
       "0                    NaN                                      NaN  \\\n",
       "1                    NaN                                      NaN   \n",
       "2                    NaN                                      NaN   \n",
       "3                    NaN                                      NaN   \n",
       "4                    NaN                                      NaN   \n",
       "5                    NaN                                      NaN   \n",
       "6                    NaN                                      NaN   \n",
       "7                    NaN                                      NaN   \n",
       "8                    NaN                                      NaN   \n",
       "9                    NaN                                      NaN   \n",
       "10                   NaN                                      NaN   \n",
       "11                   NaN                                      NaN   \n",
       "12                   NaN                                      NaN   \n",
       "13                   NaN                                      NaN   \n",
       "14                   NaN                                      NaN   \n",
       "15                   NaN                                      NaN   \n",
       "16                   NaN                                      NaN   \n",
       "17                   NaN                                      NaN   \n",
       "18                   NaN                                      NaN   \n",
       "19                   NaN                                      NaN   \n",
       "20                   NaN                                      NaN   \n",
       "21                   NaN                                      NaN   \n",
       "22                   NaN                                      NaN   \n",
       "23                   NaN                                      NaN   \n",
       "24                   NaN                                      NaN   \n",
       "25                   NaN                                      NaN   \n",
       "26                   NaN                                      NaN   \n",
       "27                   NaN                                      NaN   \n",
       "28                   NaN                                      NaN   \n",
       "29                   NaN                                      NaN   \n",
       "30                   NaN                                      NaN   \n",
       "31                   NaN                                      NaN   \n",
       "32                   NaN                                      NaN   \n",
       "33                   NaN                                      NaN   \n",
       "34                   NaN                                      NaN   \n",
       "35                   NaN                                      NaN   \n",
       "\n",
       "   disease_ontology_term_id tissue_ontology_term_id   \n",
       "0                       NaN                     NaN  \\\n",
       "1                       NaN                     NaN   \n",
       "2                       NaN                     NaN   \n",
       "3                       NaN                     NaN   \n",
       "4                       NaN                     NaN   \n",
       "5                       NaN                     NaN   \n",
       "6                       NaN                     NaN   \n",
       "7                       NaN                     NaN   \n",
       "8                       NaN                     NaN   \n",
       "9                       NaN                     NaN   \n",
       "10                      NaN                     NaN   \n",
       "11                      NaN                     NaN   \n",
       "12                      NaN                     NaN   \n",
       "13                      NaN                     NaN   \n",
       "14                      NaN                     NaN   \n",
       "15                      NaN                     NaN   \n",
       "16                      NaN                     NaN   \n",
       "17                      NaN                     NaN   \n",
       "18                      NaN                     NaN   \n",
       "19                      NaN                     NaN   \n",
       "20                      NaN                     NaN   \n",
       "21                      NaN                     NaN   \n",
       "22                      NaN                     NaN   \n",
       "23                      NaN                     NaN   \n",
       "24                      NaN                     NaN   \n",
       "25                      NaN                     NaN   \n",
       "26                      NaN                     NaN   \n",
       "27                      NaN                     NaN   \n",
       "28                      NaN                     NaN   \n",
       "29                      NaN                     NaN   \n",
       "30                      NaN                     NaN   \n",
       "31                      NaN                     NaN   \n",
       "32                      NaN                     NaN   \n",
       "33                      NaN                     NaN   \n",
       "34                      NaN                     NaN   \n",
       "35                      NaN                     NaN   \n",
       "\n",
       "   cell_type_ontology_term_id assay_ontology_term_id suspension_type DV2000   \n",
       "0                         NaN                    NaN             NaN    NaN  \\\n",
       "1                         NaN                    NaN             NaN    NaN   \n",
       "2                         NaN                    NaN             NaN    NaN   \n",
       "3                         NaN                    NaN             NaN    NaN   \n",
       "4                         NaN                    NaN             NaN    NaN   \n",
       "5                         NaN                    NaN             NaN    NaN   \n",
       "6                         NaN                    NaN             NaN    NaN   \n",
       "7                         NaN                    NaN             NaN    NaN   \n",
       "8                         NaN                    NaN             NaN    NaN   \n",
       "9                         NaN                    NaN             NaN    NaN   \n",
       "10                        NaN                    NaN             NaN    NaN   \n",
       "11                        NaN                    NaN             NaN    NaN   \n",
       "12                        NaN                    NaN             NaN    NaN   \n",
       "13                        NaN                    NaN             NaN    NaN   \n",
       "14                        NaN                    NaN             NaN    NaN   \n",
       "15                        NaN                    NaN             NaN    NaN   \n",
       "16                        NaN                    NaN             NaN    NaN   \n",
       "17                        NaN                    NaN             NaN    NaN   \n",
       "18                        NaN                    NaN             NaN    NaN   \n",
       "19                        NaN                    NaN             NaN    NaN   \n",
       "20                        NaN                    NaN             NaN    NaN   \n",
       "21                        NaN                    NaN             NaN    NaN   \n",
       "22                        NaN                    NaN             NaN    NaN   \n",
       "23                        NaN                    NaN             NaN    NaN   \n",
       "24                        NaN                    NaN             NaN    NaN   \n",
       "25                        NaN                    NaN             NaN    NaN   \n",
       "26                        NaN                    NaN             NaN    NaN   \n",
       "27                        NaN                    NaN             NaN    NaN   \n",
       "28                        NaN                    NaN             NaN    NaN   \n",
       "29                        NaN                    NaN             NaN    NaN   \n",
       "30                        NaN                    NaN             NaN    NaN   \n",
       "31                        NaN                    NaN             NaN    NaN   \n",
       "32                        NaN                    NaN             NaN    NaN   \n",
       "33                        NaN                    NaN             NaN    NaN   \n",
       "34                        NaN                    NaN             NaN    NaN   \n",
       "35                        NaN                    NaN             NaN    NaN   \n",
       "\n",
       "   pm_PH  donor_id  \n",
       "0    NaN       NaN  \n",
       "1    NaN       NaN  \n",
       "2    NaN       NaN  \n",
       "3    NaN       NaN  \n",
       "4    NaN       NaN  \n",
       "5    NaN       NaN  \n",
       "6    NaN       NaN  \n",
       "7    NaN       NaN  \n",
       "8    NaN       NaN  \n",
       "9    NaN       NaN  \n",
       "10   NaN       NaN  \n",
       "11   NaN       NaN  \n",
       "12   NaN       NaN  \n",
       "13   NaN       NaN  \n",
       "14   NaN       NaN  \n",
       "15   NaN       NaN  \n",
       "16   NaN       NaN  \n",
       "17   NaN       NaN  \n",
       "18   NaN       NaN  \n",
       "19   NaN       NaN  \n",
       "20   NaN       NaN  \n",
       "21   NaN       NaN  \n",
       "22   NaN       NaN  \n",
       "23   NaN       NaN  \n",
       "24   NaN       NaN  \n",
       "25   NaN       NaN  \n",
       "26   NaN       NaN  \n",
       "27   NaN       NaN  \n",
       "28   NaN       NaN  \n",
       "29   NaN       NaN  \n",
       "30   NaN       NaN  \n",
       "31   NaN       NaN  \n",
       "32   NaN       NaN  \n",
       "33   NaN       NaN  \n",
       "34   NaN       NaN  \n",
       "35   NaN       NaN  \n",
       "\n",
       "[36 rows x 42 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix replicate & replicate_count\n",
    "\n",
    "SAMPLE['replicate'] = \"Rep1\"\n",
    "SAMPLE['replicate_count'] = 1\n",
    "\n",
    "SAMPLE.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY = force_enum_string(STUDY, \"STUDY\", CDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in STUDY.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "All Enum fields have valid values in STUDY.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with STUDY.csv and CDE.csv\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n",
    "\n",
    "\n",
    "# Need to add contributor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in PROTOCOL.\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "github_url: 1 rows\n",
      "protocols_io_DOI: 1 rows\n",
      "\n",
      "All Enum fields have valid values in PROTOCOL.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with PROTOCOL.csv and CDE.csv\n",
    "validate_table(PROTOCOL, \"PROTOCOL\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in SUBJECT.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "sex: F, M\n",
      "race: B, W\n",
      "primary_diagnosis: normal control, idiopathic Parkinson's disease\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with SUBJECT.csv and CDE.csv\n",
    "validate_table(SUBJECT, \"SUBJECT\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUBJECT = force_enum_string(SUBJECT, \"SUBJECT\", CDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in SUBJECT.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "primary_diagnosis: Normal control, Idiopathic Parkinson's disease\n"
     ]
    }
   ],
   "source": [
    "SUBJECT['sex'] = SUBJECT['sex'].replace({'F':\"Female\", 'M':\"Male\"})\n",
    "SUBJECT['race'] = SUBJECT['race'].replace({'W':\"White\", 'B':\"Black or African American\"})\n",
    "\n",
    "SUBJECT['primary_diagnosis'] = SUBJECT['primary_diagnosis'].replace({'normal control':\"Healthy Control\", \"idiopathic Parkinson's disease\":\"Idiopathic PD\"})\n",
    "validate_table(SUBJECT, \"SUBJECT\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in SAMPLE.\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "source_RIN: 36 rows\n",
      "RIN: 36 rows\n",
      "file_description: 36 rows\n",
      "time: 36 rows\n",
      "header: 36 rows\n",
      "annotation: 36 rows\n",
      "configuration_file: 36 rows\n",
      "organism_ontology_term_id: 36 rows\n",
      "development_stage_ontology_term_id: 36 rows\n",
      "sex_ontology_term_id: 36 rows\n",
      "self_reported_ethnicity_ontology_term_id: 36 rows\n",
      "disease_ontology_term_id: 36 rows\n",
      "tissue_ontology_term_id: 36 rows\n",
      "cell_type_ontology_term_id: 36 rows\n",
      "assay_ontology_term_id: 36 rows\n",
      "suspension_type: 36 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "molecular_source: nuclear RNA\n",
      "assay: v3.1 - Single Index, 10x Genomics \n",
      "sequencing_end: paired-end\n",
      "sequencing_length: 150bp x2\n",
      "technology: sN\n",
      "adjustment: raw\n",
      "content: reads\n",
      "organism_ontology_term_id: nan\n",
      "sex_ontology_term_id: nan\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with SAMPLE.csv and CDE.csv\n",
    "validate_table(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "# sequence length will need to be converted to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = force_enum_string(SAMPLE, \"SAMPLE\", CDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force the right sex_ontology_term_id\n",
    "SAMPLE[\"organism_ontology_term_id\"] = \"NCBITaxon:9606\"\n",
    "\n",
    "# set time == 0 for all samples\n",
    "SAMPLE['time'] = 0\n",
    "\n",
    "SAMPLE['file_type'] = SAMPLE['file_type'].replace({\"Fastq\":\"fastq\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# need to join with subject to get \"sex\" and convert to ontology term\n",
    "SAMPLE_SUBJECT = SAMPLE.merge(SUBJECT, on='subject_id',  how='left')\n",
    "SAMPLE_og = SAMPLE.copy()\n",
    "SAMPLE['sex_ontology_term_id'] = SAMPLE_SUBJECT['sex'].replace({\"Male\":\"PATO:0000384 (male)\", \"Female\":\"PATO:0000383 (female)\" })\n",
    "\n",
    "# ignore development_stage_ontology_term_id, self_reported_ethnicity_ontology_term_id, assay_ontology_term_id, etc for now. (Check wiht Le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix assay\n",
    "SAMPLE['assay'] = SAMPLE['assay'].replace({'v3.1 - Single Index, 10x Genomics ':\"v3.1 - Single Index\"})\n",
    "# fix assay\n",
    "SAMPLE['sequencing_length'] = SAMPLE['sequencing_length'].replace({'150bp x2':\"150\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in CLINPATH: path_thal\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "time_from_baseline: 12 rows\n",
      "GP2_id: 12 rows\n",
      "AMPPD_id: 12 rows\n",
      "last_diagnosis: 12 rows\n",
      "age_at_onset: 12 rows\n",
      "age_at_diagnosis: 12 rows\n",
      "first_motor_symptom: 12 rows\n",
      "hx_dementia_mci: 12 rows\n",
      "hx_melanoma: 12 rows\n",
      "education_level: 12 rows\n",
      "smoking_status: 12 rows\n",
      "path_autopsy_dx_main: 6 rows\n",
      "path_year_death: 12 rows\n",
      "cause_death: 12 rows\n",
      "brain_weight: 12 rows\n",
      "path_braak_nft: 12 rows\n",
      "path_braak_asyn: 12 rows\n",
      "path_cerad: 12 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "region_level_2: Prefrontal cortex\n",
      "hx_dementia_mci: nan\n",
      "hx_melanoma: nan\n",
      "education_level: nan\n",
      "smoking_status: nan\n",
      "APOE_e4_status: 3,3, 2,3\n",
      "cognitive_status: normal\n",
      "path_autopsy_dx_main: nan\n",
      "path_braak_nft: nan\n",
      "path_braak_asyn: nan\n",
      "path_cerad: nan\n",
      "known_pathogenic_mutation: nan\n",
      "path_mckeith: nan\n",
      "sn_neuronal_loss: nan\n",
      "path_infarcs: nan\n",
      "path_nia_ri: nan\n",
      "path_nia_aa_a: nan\n",
      "path_nia_aa_b: nan\n",
      "path_nia_aa_c: nan\n",
      "TDP43: nan\n",
      "arteriolosclerosis_severity_scale: nan\n",
      "amyloid_angiopathy_severity_scale: nan\n",
      "path_ad_level: nan\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with CLINPATH.csv and CDE.csv\n",
    "validate_table(CLINPATH, \"CLINPATH\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLINPATH = force_enum_string(CLINPATH, \"CLINPATH\", CDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redact \"Prefrontal Cortex\" from region_level_2 for now\n",
    "CLINPATH['region_level_2'] = CLINPATH['region_level_2'].replace({'Prefrontal Cortex':\"NaN\"})\n",
    "\n",
    "# leave te APOE_e4_status as is for now . multiple are coded as \"2,3\" \n",
    "# but remove commas\n",
    "CLINPATH[\"APOE_e4_status\"] = CLINPATH[\"APOE_e4_status\"].str.replace(\",\",\"\")\n",
    "\n",
    "# need to fix the path_autopsy_dx_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ergonyc/Projects/ASAP/team-hafler')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_path / \"team-hafler\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the column order\n",
    "STUDY = reorder_table_to_CDE(STUDY, \"STUDY\", CDE)\n",
    "SAMPLE = reorder_table_to_CDE(SAMPLE, \"SAMPLE\", CDE)\n",
    "PROTOCOL = reorder_table_to_CDE(PROTOCOL, \"PROTOCOL\", CDE)\n",
    "SUBJECT = reorder_table_to_CDE(SUBJECT, \"SUBJECT\", CDE)     \n",
    "CLINPATH = reorder_table_to_CDE(CLINPATH, \"CLINPATH\", CDE)\n",
    "\n",
    "# write the clean metadata\n",
    "STUDY.to_csv(data_path / \"metadata/STUDY.csv\")\n",
    "PROTOCOL.to_csv(data_path / \"metadata/PROTOCOL.csv\")\n",
    "CLINPATH.to_csv(data_path / \"metadata/CLINPATH.csv\")\n",
    "SAMPLE.to_csv(data_path / \"metadata/SAMPLE.csv\")\n",
    "SUBJECT.to_csv(data_path / \"metadata/SUBJECT.csv\")\n",
    "\n",
    "# also writh them to clean...\n",
    "# \n",
    "#  \n",
    "\n",
    "export_root = Path.cwd() / \"clean/team-Hafler\"\n",
    "if not export_root.exists():\n",
    "    export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "STUDY.to_csv( export_root / \"STUDY.csv\")\n",
    "PROTOCOL.to_csv(export_root / \"PROTOCOL.csv\")\n",
    "SAMPLE.to_csv(export_root / \"SAMPLE.csv\")\n",
    "SUBJECT.to_csv(export_root / \"SUBJECT.csv\")\n",
    "CLINPATH.to_csv(export_root / \"CLINPATH.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY.to_csv( metadata_path / \"STUDY.csv\")\n",
    "CLINPATH.to_csv( metadata_path / \"CLINPATH.csv\")\n",
    "SUBJECT.to_csv( metadata_path / \"SUBJECT.csv\")\n",
    "SAMPLE.to_csv( metadata_path / \"SAMPLE.csv\")\n",
    "PROTOCOL.to_csv( metadata_path / \"PROTOCOL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[\"33\", \"34\", \"44\", \"Unknown\"]'], dtype=object)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLINPATH[\"APOE_e4_status\"].unique()\n",
    "\n",
    "CDE[CDE[\"Field\"]== \"APOE_e4_status\"].Validation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert \n",
    "data_path = Path.home() / (\"Projects/ASAP/team-hardy\")\n",
    "metadata_path = data_path / \"metadata\"\n",
    "\n",
    "SUBJECT = pd.read_csv(f\"{metadata_path}/SUBJECT.csv\")\n",
    "CLINPATH = pd.read_csv(f\"{metadata_path}/CLINPATH.csv\")\n",
    "STUDY = pd.read_csv(f\"{metadata_path}/STUDY.csv\")\n",
    "PROTOCOL = pd.read_csv(f\"{metadata_path}/PROTOCOL.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there seems to be something funky with SAMPLE\n",
    "SAMPLE = pd.read_csv(f\"{metadata_path}/SAMPLE.csv\", index_col=0).reindex(axis=1)\n",
    "# SAMPLE = SAMPLE[SAMPLE[\"batch\"]==\"B1\"]\n",
    "SAMPLE.drop_duplicates(inplace=True) #, subset=[ \"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112.53125, 4416, 3616)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(SAMPLE.shape[0]-15)/32, 138*8*4, len(SAMPLE[\"file_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project_description</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Ryten Lab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                              value\n",
       "0         project_name  Understanding mechanisms of Parkinson's diseas...\n",
       "1      project_dataset                                    Hardy snRNA-seq\n",
       "2  project_description  Genetic analysis has identified many risk gene...\n",
       "3       ASAP_team_name                                         TEAM-HARDY\n",
       "4        ASAP_lab_name                                          Ryten Lab"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STUDY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb Cell 68\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# ALTERNATIVE call\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m base_path \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39m/path/to/files\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mfile_MD5\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: compute_md5(base_path \u001b[39m/\u001b[39m x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_md5_mac\u001b[39m(file_path):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m    Compute the MD5 hash of a file using the `md5` command on a Mac.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m    - str: MD5 hash of the file.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/ASAP/meta-clean/meta_clean.ipynb#Y202sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_md5(file_path):\n",
    "    \"\"\"\n",
    "    Compute the MD5 hash of a file.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str/Path): Path to the file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: MD5 hash of the file.\n",
    "    \"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "# ALTERNATIVE call\n",
    "# Example usage\n",
    "base_path = Path('/path/to/files')\n",
    "data['file_MD5'] = data['file_name'].apply(lambda x: compute_md5(base_path / x))\n",
    "\n",
    "\n",
    "def compute_md5_mac(file_path):\n",
    "    \"\"\"\n",
    "    Compute the MD5 hash of a file using the `md5` command on a Mac.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str/Path): Path to the file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: MD5 hash of the file.\n",
    "    \"\"\"\n",
    "    result = subprocess.run(['md5', '-q', file_path], capture_output=True, text=True)\n",
    "    return result.stdout.strip()\n",
    "\n",
    "# Example usage (to be run in your local environment):\n",
    "# base_path = Path('/path/to/files')\n",
    "# data['file_MD5'] = data['file_name'].apply(lambda x: compute_md5_mac(base_path / x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project_name</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>project_description</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>PI_full_name</td>\n",
       "      <td>PI_email</td>\n",
       "      <td>contributor_names</td>\n",
       "      <td>submitter_name</td>\n",
       "      <td>submitter_email</td>\n",
       "      <td>...</td>\n",
       "      <td>other_funding_source</td>\n",
       "      <td>publication_DOI</td>\n",
       "      <td>publication_PMID</td>\n",
       "      <td>number_of_brain_samples</td>\n",
       "      <td>brain_regions</td>\n",
       "      <td>types_of_samples</td>\n",
       "      <td>PI_ORCHID</td>\n",
       "      <td>PI_google_scholar_id</td>\n",
       "      <td>DUA_version</td>\n",
       "      <td>metadata_version_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "      <td>Ryten Lab</td>\n",
       "      <td>Mina Ryten</td>\n",
       "      <td>mina.ryten@ucl.ac.uk</td>\n",
       "      <td>Aine Fairbrother-Browne, Jonathan Brenton, Mel...</td>\n",
       "      <td>Aine Fairbrother-Browne</td>\n",
       "      <td>aine.fairbrother-browne.18@ucl.ac.uk</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>Inferior Parietal Lobule (IPL), Anterior Cingu...</td>\n",
       "      <td>Late stage (Braak 5-6) PD and control post-mor...</td>\n",
       "      <td>0000-0001-9520-6957</td>\n",
       "      <td>https://scholar.google.co.uk/citations?user=lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Version 1, 09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0                1    \n",
       "0                                       project_name  project_dataset  \\\n",
       "1  Understanding mechanisms of Parkinson's diseas...  Hardy snRNA-seq   \n",
       "\n",
       "                                                  2               3    \n",
       "0                                project_description  ASAP_team_name  \\\n",
       "1  Genetic analysis has identified many risk gene...      TEAM-HARDY   \n",
       "\n",
       "              4             5                     6    \n",
       "0  ASAP_lab_name  PI_full_name              PI_email  \\\n",
       "1      Ryten Lab    Mina Ryten  mina.ryten@ucl.ac.uk   \n",
       "\n",
       "                                                  7                        8    \n",
       "0                                  contributor_names           submitter_name  \\\n",
       "1  Aine Fairbrother-Browne, Jonathan Brenton, Mel...  Aine Fairbrother-Browne   \n",
       "\n",
       "                                     9   ...                    11   \n",
       "0                       submitter_email  ...  other_funding_source  \\\n",
       "1  aine.fairbrother-browne.18@ucl.ac.uk  ...                   NaN   \n",
       "\n",
       "                12                13                       14   \n",
       "0  publication_DOI  publication_PMID  number_of_brain_samples  \\\n",
       "1              NaN               NaN                      128   \n",
       "\n",
       "                                                  15   \n",
       "0                                      brain_regions  \\\n",
       "1  Inferior Parietal Lobule (IPL), Anterior Cingu...   \n",
       "\n",
       "                                                  16                   17   \n",
       "0                                   types_of_samples            PI_ORCHID  \\\n",
       "1  Late stage (Braak 5-6) PD and control post-mor...  0000-0001-9520-6957   \n",
       "\n",
       "                                                  18           19   \n",
       "0                               PI_google_scholar_id  DUA_version  \\\n",
       "1  https://scholar.google.co.uk/citations?user=lt...          NaN   \n",
       "\n",
       "                      20  \n",
       "0  metadata_version_date  \n",
       "1     Version 1, 09/2023  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fix STUDY formatting\n",
    "tmp = pd.DataFrame()\n",
    "tmp = STUDY[[\"name\",\"value\"]].transpose().reset_index().drop(columns=[\"index\"])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_dataset</th>\n",
       "      <th>project_description</th>\n",
       "      <th>ASAP_team_name</th>\n",
       "      <th>ASAP_lab_name</th>\n",
       "      <th>PI_full_name</th>\n",
       "      <th>PI_email</th>\n",
       "      <th>contributor_names</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submitter_email</th>\n",
       "      <th>...</th>\n",
       "      <th>other_funding_source</th>\n",
       "      <th>publication_DOI</th>\n",
       "      <th>publication_PMID</th>\n",
       "      <th>number_of_brain_samples</th>\n",
       "      <th>brain_regions</th>\n",
       "      <th>types_of_samples</th>\n",
       "      <th>PI_ORCHID</th>\n",
       "      <th>PI_google_scholar_id</th>\n",
       "      <th>DUA_version</th>\n",
       "      <th>metadata_version_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Understanding mechanisms of Parkinson's diseas...</td>\n",
       "      <td>Hardy snRNA-seq</td>\n",
       "      <td>Genetic analysis has identified many risk gene...</td>\n",
       "      <td>TEAM-HARDY</td>\n",
       "      <td>Ryten Lab</td>\n",
       "      <td>Mina Ryten</td>\n",
       "      <td>mina.ryten@ucl.ac.uk</td>\n",
       "      <td>Aine Fairbrother-Browne, Jonathan Brenton, Mel...</td>\n",
       "      <td>Aine Fairbrother-Browne</td>\n",
       "      <td>aine.fairbrother-browne.18@ucl.ac.uk</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>Inferior Parietal Lobule (IPL), Anterior Cingu...</td>\n",
       "      <td>Late stage (Braak 5-6) PD and control post-mor...</td>\n",
       "      <td>0000-0001-9520-6957</td>\n",
       "      <td>https://scholar.google.co.uk/citations?user=lt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Version 1, 09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                       project_name  project_dataset   \n",
       "1  Understanding mechanisms of Parkinson's diseas...  Hardy snRNA-seq  \\\n",
       "\n",
       "0                                project_description ASAP_team_name   \n",
       "1  Genetic analysis has identified many risk gene...     TEAM-HARDY  \\\n",
       "\n",
       "0 ASAP_lab_name PI_full_name              PI_email   \n",
       "1     Ryten Lab   Mina Ryten  mina.ryten@ucl.ac.uk  \\\n",
       "\n",
       "0                                  contributor_names           submitter_name   \n",
       "1  Aine Fairbrother-Browne, Jonathan Brenton, Mel...  Aine Fairbrother-Browne  \\\n",
       "\n",
       "0                       submitter_email  ... other_funding_source   \n",
       "1  aine.fairbrother-browne.18@ucl.ac.uk  ...                  NaN  \\\n",
       "\n",
       "0 publication_DOI publication_PMID number_of_brain_samples   \n",
       "1             NaN              NaN                     128  \\\n",
       "\n",
       "0                                      brain_regions   \n",
       "1  Inferior Parietal Lobule (IPL), Anterior Cingu...  \\\n",
       "\n",
       "0                                   types_of_samples            PI_ORCHID   \n",
       "1  Late stage (Braak 5-6) PD and control post-mor...  0000-0001-9520-6957  \\\n",
       "\n",
       "0                               PI_google_scholar_id DUA_version   \n",
       "1  https://scholar.google.co.uk/citations?user=lt...         NaN  \\\n",
       "\n",
       "0 metadata_version_date  \n",
       "1    Version 1, 09/2023  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp.columns = tmp.iloc[0]\n",
    "STUDY = tmp.drop([0])\n",
    "STUDY.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in STUDY: submittor_email\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "other_funding_source: 1 rows\n",
      "publication_DOI: 1 rows\n",
      "publication_PMID: 1 rows\n",
      "DUA_version: 1 rows\n",
      "\n",
      "All Enum fields have valid values in STUDY.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with STUDY.csv and CDE.csv\n",
    "validate_table(STUDY, \"STUDY\", CDE)\n",
    "\n",
    "\n",
    "# Need to add contributor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_collection_summary</td>\n",
       "      <td>This dataset contains cortical regions only, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell_extraction_summary</td>\n",
       "      <td>From protocols.io: This protocol is used to is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lib_prep_summary</td>\n",
       "      <td>'Nuclei were extracted from homogenised post-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_processing_summary</td>\n",
       "      <td>Cell ranger was used to convert raw sequencing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>github_url</td>\n",
       "      <td>Raw to fastq to mapped: https://github.com/RHR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name   \n",
       "0  sample_collection_summary  \\\n",
       "1    cell_extraction_summary   \n",
       "2           lib_prep_summary   \n",
       "3    data_processing_summary   \n",
       "4                 github_url   \n",
       "\n",
       "                                               value  \n",
       "0  This dataset contains cortical regions only, p...  \n",
       "1  From protocols.io: This protocol is used to is...  \n",
       "2  'Nuclei were extracted from homogenised post-m...  \n",
       "3  Cell ranger was used to convert raw sequencing...  \n",
       "4  Raw to fastq to mapped: https://github.com/RHR...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROTOCOL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_collection_summary</th>\n",
       "      <th>cell_extraction_summary</th>\n",
       "      <th>lib_prep_summary</th>\n",
       "      <th>data_processing_summary</th>\n",
       "      <th>github_url</th>\n",
       "      <th>protocols_io_DOI</th>\n",
       "      <th>other_reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This dataset contains cortical regions only, p...</td>\n",
       "      <td>From protocols.io: This protocol is used to is...</td>\n",
       "      <td>'Nuclei were extracted from homogenised post-m...</td>\n",
       "      <td>Cell ranger was used to convert raw sequencing...</td>\n",
       "      <td>Raw to fastq to mapped: https://github.com/RHR...</td>\n",
       "      <td>Nuclear extraction protocol: 10.17504/protocol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                          sample_collection_summary   \n",
       "1  This dataset contains cortical regions only, p...  \\\n",
       "\n",
       "0                            cell_extraction_summary   \n",
       "1  From protocols.io: This protocol is used to is...  \\\n",
       "\n",
       "0                                   lib_prep_summary   \n",
       "1  'Nuclei were extracted from homogenised post-m...  \\\n",
       "\n",
       "0                            data_processing_summary   \n",
       "1  Cell ranger was used to convert raw sequencing...  \\\n",
       "\n",
       "0                                         github_url   \n",
       "1  Raw to fastq to mapped: https://github.com/RHR...  \\\n",
       "\n",
       "0                                   protocols_io_DOI other_reference  \n",
       "1  Nuclear extraction protocol: 10.17504/protocol...             NaN  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix STUDY formatting\n",
    "tmp = pd.DataFrame()\n",
    "tmp = PROTOCOL[[\"name\",\"value\"]].transpose().reset_index().drop(columns=[\"index\"])\n",
    "tmp.columns = tmp.iloc[0]\n",
    "PROTOCOL = tmp.drop([0])\n",
    "PROTOCOL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in PROTOCOL.\n",
      "\n",
      "No empty or NaN values found in required fields.\n",
      "\n",
      "All Enum fields have valid values in PROTOCOL.\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with PROTOCOL.csv and CDE.csv\n",
    "validate_table(PROTOCOL, \"PROTOCOL\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in SUBJECT.\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "race: 128 rows\n",
      "ethnicity: 128 rows\n",
      "duration_pmi: 2 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "race: nan\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with SUBJECT.csv and CDE.csv\n",
    "validate_table(SUBJECT, \"SUBJECT\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in SAMPLE: sample_id, source_sample_id\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "subject_id: 16 rows\n",
      "replicate: 3328 rows\n",
      "replicate_count: 16 rows\n",
      "repeated_sample: 16 rows\n",
      "tissue: 16 rows\n",
      "brain_region: 16 rows\n",
      "source_RIN: 3616 rows\n",
      "RIN: 16 rows\n",
      "molecular_source: 16 rows\n",
      "input_cell_count: 304 rows\n",
      "assay: 16 rows\n",
      "sequencing_end: 16 rows\n",
      "sequencing_length: 16 rows\n",
      "sequencing_instrument: 16 rows\n",
      "file_type: 16 rows\n",
      "technology: 16 rows\n",
      "omic: 16 rows\n",
      "adjustment: 16 rows\n",
      "content: 16 rows\n",
      "time: 16 rows\n",
      "header: 3616 rows\n",
      "annotation: 3616 rows\n",
      "configuration_file: 3616 rows\n",
      "organism_ontology_term_id: 16 rows\n",
      "development_stage_ontology_term_id: 16 rows\n",
      "sex_ontology_term_id: 16 rows\n",
      "self_reported_ethnicity_ontology_term_id: 3616 rows\n",
      "disease_ontology_term_id: 80 rows\n",
      "tissue_ontology_term_id: 16 rows\n",
      "cell_type_ontology_term_id: 3616 rows\n",
      "assay_ontology_term_id: 16 rows\n",
      "suspension_type: 16 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "molecular_source: nuclear RNA, nan\n",
      "assay: nan\n",
      "sequencing_end: paired-end, nan\n",
      "sequencing_length: 190.0, nan\n",
      "sequencing_instrument: nan\n",
      "file_type: nan\n",
      "technology: sN, nan\n",
      "omic: nan\n",
      "adjustment: raw, nan\n",
      "content: reads, nan\n",
      "organism_ontology_term_id: HUMAN NCBITaxon:9606, nan\n",
      "sex_ontology_term_id: nan\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with SAMPLE.csv and CDE.csv\n",
    "validate_table(SAMPLE, \"SAMPLE\", CDE)\n",
    "\n",
    "# sequence length will need to be converted to a string\n",
    "\n",
    "# add 'replicate' coding (nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3616"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SAMPLE[\"file_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Required Fields in CLINPATH: source_sample_id\n",
      "\n",
      "Fields with Empty or NaN values:\n",
      "GP2_id: 4 rows\n",
      "hemisphere: 10 rows\n",
      "AMPPD_id: 138 rows\n",
      "family_history: 138 rows\n",
      "last_diagnosis: 138 rows\n",
      "age_at_onset: 138 rows\n",
      "age_at_diagnosis: 10 rows\n",
      "first_motor_symptom: 138 rows\n",
      "hx_dementia_mci: 10 rows\n",
      "hx_melanoma: 138 rows\n",
      "education_level: 138 rows\n",
      "smoking_status: 138 rows\n",
      "APOE_e4_status: 138 rows\n",
      "cognitive_status: 138 rows\n",
      "path_autopsy_dx_main: 10 rows\n",
      "path_year_death: 138 rows\n",
      "age_at_death: 10 rows\n",
      "cause_death: 10 rows\n",
      "brain_weight: 138 rows\n",
      "path_braak_nft: 10 rows\n",
      "path_braak_asyn: 10 rows\n",
      "path_cerad: 64 rows\n",
      "path_thal: 10 rows\n",
      "\n",
      "Invalid Field/Value pairs:\n",
      "hemisphere: nan\n",
      "family_history: nan\n",
      "hx_dementia_mci: nan\n",
      "hx_melanoma: nan\n",
      "education_level: nan\n",
      "smoking_status: nan\n",
      "APOE_e4_status: nan\n",
      "cognitive_status: nan\n",
      "path_autopsy_dx_main: Control brain, Pathological ageing, Control brain / Path ageing, Argyrophilic grain disease, Control brain, Cerebrovascular disease (small vessel), Cerebrovascular disease (small vessel), Control brain, Alzheimer`s disease (intermediate level AD pathological change), Control brain / Path ageing, CAA, nan\n",
      "path_braak_nft: 2.0, 1.0, 3.0, 0.0, 4.0, 6.0, nan\n",
      "path_braak_asyn: 6.0, 0.0, 5.0, nan\n",
      "path_cerad: nan\n",
      "path_thal: At least 4, nan\n",
      "known_pathogenic_mutation: nan\n",
      "path_mckeith: Diffuse neocortical, Limbic transitional, Diffuse Neocortical, nan\n",
      "sn_neuronal_loss: nan\n",
      "path_infarcs: nan\n",
      "path_nia_ri: nan\n",
      "path_nia_aa_a: 1.0, 2.0, 0.0, 3.0, nan\n",
      "path_nia_aa_b: 1.0, 2.0, 0.0, 3.0, nan\n",
      "path_nia_aa_c: 0.0, 1.0, 2.0, 3.0, nan\n",
      "TDP43: nan\n",
      "arteriolosclerosis_severity_scale: nan\n",
      "amyloid_angiopathy_severity_scale: nan\n",
      "path_ad_level: nan, No evidence\n",
      "dig_slide_avail: Yes\n",
      "quant_path_avail: Yes\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with CLINPATH.csv and CDE.csv\n",
    "validate_table(CLINPATH, \"CLINPATH\", CDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scverse10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
